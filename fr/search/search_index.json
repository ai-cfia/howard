{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Le projet Howard","text":""},{"location":"#howard-infrastructure-cloud-de-lagence-canadienne-dinspection-des-aliments-acia-acia-cfia-ai-lab","title":"Howard : Infrastructure Cloud de l'Agence canadienne d'inspection des aliments (ACIA) ACIA-CFIA ai-Lab","text":""},{"location":"#a-propos-du-projet","title":"\u00c0 propos du projet","text":"<p>Le projet Howard est nomm\u00e9 d'apr\u00e8s Luke Howard, FRS, un chimiste manufacturier et m\u00e9t\u00e9orologue amateur britannique notable connu sous le nom de \"Le Parrain des Nuages\". Son travail a jet\u00e9 les bases de concepts en m\u00e9t\u00e9orologie, notamment un syst\u00e8me de nomenclature pour les nuages introduit en 1802. Inspir\u00e9 par son innovation et son h\u00e9ritage dans la cat\u00e9gorisation des \u00e9l\u00e9ments, notre projet vise \u00e0 g\u00e9rer et orchestrer efficacement l'infrastructure bas\u00e9e sur le cloud pour le laboratoire d'intelligence artificielle (ai-lab) de l'Agence canadienne d'inspection des aliments (ACIA).</p> <p>Howard est essentiellement la colonne vert\u00e9brale qui soutient l'environnement Kubernetes du laboratoire d'intelligence artificielle de l'ACIA, o\u00f9 des applications cl\u00e9s telles que Nachet, Finesse et Louis sont d\u00e9ploy\u00e9es et g\u00e9r\u00e9es de mani\u00e8re dynamique. Cette infrastructure met l'accent sur la robustesse, la s\u00e9curit\u00e9 et l'efficacit\u00e9 pour traiter la charge de travail critique impliqu\u00e9e dans l'inspection et la s\u00e9curit\u00e9 alimentaire.</p>"},{"location":"#ensemble-de-technologies-et-outils","title":"Ensemble de technologies et outils","text":"<p>L'infrastructure Howard s'appuie sur une suite compl\u00e8te d'outils con\u00e7us pour fournir un environnement r\u00e9silient, s\u00e9curis\u00e9 et \u00e9volutif :</p>"},{"location":"#fournisseurs-de-cloud","title":"Fournisseurs de cloud","text":"<ul> <li>Initialement h\u00e9berg\u00e9e sur Google Cloud, l'infrastructure a \u00e9t\u00e9 transf\u00e9r\u00e9e sur Azure.</li> </ul>"},{"location":"#orchestration-des-conteneurs","title":"Orchestration des conteneurs","text":"<p>Kubernetes : Orchestrer le d\u00e9ploiement, la mise \u00e0 l'\u00e9chelle et la gestion des conteneurs.</p>"},{"location":"#gitops","title":"GitOps","text":"<p>ArgoCD : Utilis\u00e9 pour la livraison continue, gestion des ressources Kubernetes de mani\u00e8re d\u00e9clarative via des d\u00e9p\u00f4ts Git.</p>"},{"location":"#surveillance-et-securite","title":"Surveillance et s\u00e9curit\u00e9","text":"<ul> <li>Grafana : Logiciel de visualisation et d'analytique.</li> <li>Kube-Prometheus-Stack : Surveillance compl\u00e8te des clusters Kubernetes avec Prometheus.</li> <li>Falco : Outil de s\u00e9curit\u00e9 open-source en temps r\u00e9el.</li> <li>Trivy : Scanner de vuln\u00e9rabilit\u00e9s pour les conteneurs.</li> <li>Oneuptime : Outil de surveillance pour des informations sur la performance et la s\u00e9curit\u00e9 en temps r\u00e9el.</li> </ul>"},{"location":"#reseautage","title":"R\u00e9seautage","text":"<ul> <li>Vouch-Proxy : Proxy d'authentification.</li> <li>Nginx Ingress : Contr\u00f4leur d'entr\u00e9e pour Kubernetes utilisant NGINX comme proxy inverse et \u00e9quilibreuse de charge.</li> <li>Istio : Maillage de services qui fournit une interface s\u00e9curis\u00e9e pour la communication entre services.</li> </ul>"},{"location":"#gestion-des-secrets","title":"Gestion des secrets","text":"<p>HashiCorp Vault : S\u00e9curise, stocke et contr\u00f4le strictement l'acc\u00e8s aux jetons, mots de passe, certificats et autres secrets.</p>"},{"location":"#gestion-de-linfrastructure-cloud","title":"Gestion de l'infrastructure cloud","text":"<ul> <li>Terraform : Outil open-source d'infrastructure en tant que code permettant de g\u00e9rer le cycle de vie des services chez les fournisseurs cloud de mani\u00e8re d\u00e9clarative.</li> <li>Ansible : Outil d'automatisation pour la configuration et la gestion des ordinateurs.</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#deploiement-terraform","title":"D\u00e9ploiement Terraform","text":"<p>La configuration actuelle h\u00e9berge un cluster Kubernetes sur Azure (AKS). Nous disposons d'un pipeline Azure DevOps apply-terraform.yml qui applique les ressources Terraform cr\u00e9\u00e9es sur notre abonnement Azure. L'\u00e9tat est ensuite sauvegard\u00e9 dans un stockage blob d'Azure.</p>"},{"location":"#configuration-de-kubectl","title":"Configuration de Kubectl","text":"<p>En supposant que vous ayez install\u00e9 Azure CLI et le plugin kubelogin, voici comment r\u00e9cup\u00e9rer localement la configuration kube :</p> <pre><code>az login\naz account set --subscription xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\naz aks get-credentials --resource-group resource-group-name --name aks-name --overwrite-existing\nkubelogin convert-kubeconfig -l azurecli\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>https://ai-cfia.github.io/howard/fr/</p>"},{"location":"adr/","title":"Architectural decision records (ADR)","text":"<ul> <li>Infrastructure</li> <li>GitOps</li> <li>Gestion des secrets</li> <li>Infrastructure en code</li> <li>Conteneurs</li> <li>Gestion de l'authentification</li> <li>R\u00e9seautique</li> <li>S\u00e9curiter</li> </ul>"},{"location":"adr/#plus-de-configuration-implementation","title":"Plus de configuration / implementation","text":"<ul> <li>Ansible</li> </ul>"},{"location":"ansible/","title":"Playbooks Ansible","text":""},{"location":"ansible/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>Dans le cadre de nos t\u00e2ches, nous avons cherch\u00e9 \u00e0 cr\u00e9er des machines virtuelles (VM) pour faciliter le travail des d\u00e9veloppeurs. Les besoins suivants ont \u00e9t\u00e9 mentionn\u00e9s :</p> <ul> <li> <p>Tester les applications avant de demander \u00e0 l'informatique d'installer les logiciels sur nos ordinateurs portables personnels.</p> </li> <li> <p>Faciliter le travail de certains d\u00e9veloppeurs (par exemple, avoir des CLI d\u00e9j\u00e0 install\u00e9s et configur\u00e9s).</p> </li> </ul> <p>Pour configurer des machines virtuelles dans le cloud, l'utilisation d'Ansible s'est av\u00e9r\u00e9e tr\u00e8s utile pour permettre l'\u00e9volutivit\u00e9 en cas de besoin de plus de VM \u00e0 l'avenir.</p>"},{"location":"ansible/#glossaire","title":"Glossaire","text":"<p>Ansible : Ansible est un outil logiciel open-source pour l'automatisation informatique. Il automatise le provisionnement, la configuration et le d\u00e9ploiement des serveurs et des applications. Ansible est sans agent, ce qui signifie qu'aucun logiciel n'a besoin d'\u00eatre install\u00e9 sur les machines qu'il g\u00e8re. Il utilise SSH pour se connecter aux machines et ex\u00e9cuter des commandes.</p> <p>Machine virtuelle (VM) : Une machine virtuelle est un logiciel qui simule un ordinateur complet, avec son propre syst\u00e8me d'exploitation et ses applications, et s'ex\u00e9cute sur un ordinateur physique. En bref, c'est un ordinateur virtuel \u00e0 l'int\u00e9rieur d'un ordinateur physique.</p>"},{"location":"ansible/#diagrammes","title":"Diagrammes","text":""},{"location":"ansible/#references","title":"R\u00e9f\u00e9rences","text":"<p>Kubernetes</p> <p>Pod</p> <p>HA</p> <p>\u00c9quilibreur de charge</p>"},{"location":"auth-workflow/","title":"Documentation de Vouch-Proxy","text":""},{"location":"auth-workflow/#vue-densemble","title":"Vue d'ensemble","text":"<p>Vouch-Proxy est une solution d'authentification et d'autorisation qui agit comme un compagnon pour notre contr\u00f4leur d'ingress Nginx. Il est con\u00e7u pour authentifier les utilisateurs via un fournisseur OpenID Connect (OIDC) puis passer ces informations d'identification valid\u00e9es \u00e0 notre application web.</p>"},{"location":"auth-workflow/#integration-avec-azure-active-directory","title":"Int\u00e9gration avec Azure Active Directory","text":"<p>Vouch-Proxy peut \u00eatre configur\u00e9 pour authentifier les utilisateurs via Azure Active Directory (Azure AD), en utilisant les enregistrements d'applications d'Azure pour authentifier les utilisateurs d'un locataire Azure AD sp\u00e9cifique. Cette configuration implique :</p> <ul> <li>La cr\u00e9ation d'un enregistrement d'application dans Azure AD.</li> <li>La configuration des URI de redirection pour l'enregistrement d'application \u00e0   <code>&lt;https://vouch.inspection.alpha.canada.ca/auth&gt;</code></li> <li>L'utilisation des d\u00e9tails de l'enregistrement d'application (ID client, secret client, tenantID) dans la configuration de Vouch-Proxy :</li> </ul> <pre><code>  client_id: &lt;id&gt;\n  client_secret: &lt;secret&gt;\n  auth_url: https://login.microsoftonline.com/&lt;tenantID&gt;/oauth2/v2.0/authorize\n  token_url: https://login.microsoftonline.com/&lt;tenantID&gt;/oauth2/v2.0/token\n</code></pre> <p>Lorsqu'un utilisateur tente d'acc\u00e9der \u00e0 une ressource prot\u00e9g\u00e9e, il est redirig\u00e9 vers Azure AD pour se connecter. Une fois authentifi\u00e9, Azure AD redirige vers Vouch-Proxy, qui valide ensuite la session de l'utilisateur et transmet les d\u00e9tails d'authentification au contr\u00f4leur d'ingress Nginx.</p>"},{"location":"auth-workflow/#annotations-nginx-ingress-pour-lauthentification","title":"Annotations Nginx Ingress pour l'authentification","text":"<p>Pour prot\u00e9ger une application utilisant Vouch-Proxy, vous pouvez configurer des ressources d'ingress Nginx avec des annotations sp\u00e9cifiques. Ces annotations demandent au contr\u00f4leur Nginx de consulter Vouch-Proxy pour l'authentification avant d'accorder l'acc\u00e8s \u00e0 l'application. Voici comment configurer ces annotations pour une app avec le nom d'h\u00f4te d'ingress <code>vouch.inspection.alpha.canada.ca</code> :</p> <pre><code>annotations:\n  nginx.ingress.kubernetes.io/auth-signin: \"https://vouch.inspection.alpha.canada.ca/login?url=$scheme://$http_host$request_uri&amp;vouch-failcount=$auth_resp_failcount&amp;X-Vouch-Token=$auth_resp_jwt&amp;error=$auth_resp_err\"\n  nginx.ingress.kubernetes.io/auth-url: https://vouch.inspection.alpha.canada.ca/validate\n  nginx.ingress.kubernetes.io/auth-snippet: |\n    # these return values are used by the @error401 call\n    auth_request_set $auth_resp_jwt $upstream_http_x_vouch_jwt;\n    auth_request_set $auth_resp_err $upstream_http_x_vouch_err;\n    auth_request_set $auth_resp_failcount $upstream_http_x_vouch_failcount;\n</code></pre>"},{"location":"auth-workflow/#authentication-flow","title":"Authentication Flow","text":"<ol> <li> <p>Un utilisateur demande l'acc\u00e8s \u00e0 une application prot\u00e9g\u00e9e par Vouch-Proxy.</p> </li> <li> <p>Le contr\u00f4leur d'ingress Nginx intercepte la demande et interroge Vouch-Proxy pour valider la session de l'utilisateur.</p> </li> <li> <p>Si l'utilisateur n'est pas authentifi\u00e9, il est redirig\u00e9 vers la page de connexion Azure AD.</p> </li> <li> <p>Apr\u00e8s une authentification r\u00e9ussie, l'utilisateur est redirig\u00e9 vers Vouch-Proxy.</p> </li> <li> <p>Vouch-Proxy d\u00e9finit ensuite un cookie dans le navigateur de l'utilisateur et redirige l'utilisateur vers l'application d'origine, en transmettant les d\u00e9tails de l'utilisateur sp\u00e9cifi\u00e9s.</p> </li> </ol>"},{"location":"configuration/","title":"Configuration / implementation des ADRs dans le project Howard","text":"<ul> <li>Infrastructure</li> <li>GitOps (coming soon...)</li> <li>Gestion des secrets</li> <li>Infrastructure en code</li> <li>Conteneurs</li> <li>Gestion de l'authentification</li> <li>R\u00e9seautique</li> <li>S\u00e9curiter (coming soon...)</li> </ul>"},{"location":"configuration/#plus-de-configurations-implementations","title":"Plus de configurations / implementations","text":"<ul> <li>Ansible</li> <li>Application \u00e0 niveaux multiples</li> </ul>"},{"location":"generic-architecture/","title":"Generic architecture","text":""},{"location":"generic-architecture/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>Les diagrammes en question fournissent une repr\u00e9sentation visuelle de la strat\u00e9gie d'infrastructure planifi\u00e9e pour le laboratoire d'intelligence artificielle de l'Agence Canadienne d'Inspection des Aliments (ACIA). La raison de ce design est de r\u00e9pondre aux besoins des utilisateurs r\u00e9partis sur la vaste \u00e9tendue du Canada, y compris les principaux groupes d'utilisateurs dans le centre et l'est du Canada. En \u00e9tablissant deux clusters dans les r\u00e9gions g\u00e9ographiques centrales et orientales du Canada, l'ACIA vise \u00e0 offrir un service optimal \u00e0 tous les utilisateurs, quel que soit leur emplacement. Cette approche non seulement assure une haute disponibilit\u00e9 (HA) en r\u00e9duisant le risque d'interruption de service due \u00e0 des pannes r\u00e9gionales, mais maintient \u00e9galement une redondance un-\u00e0-un de tous les services, ce qui est crucial pour la reprise apr\u00e8s sinistre et les op\u00e9rations ininterrompues. Le placement strat\u00e9gique de ces clusters permet une r\u00e9plication efficace des donn\u00e9es et des processus de basculement rapides, offrant ainsi une infrastructure robuste et fiable pour les op\u00e9rations critiques de l'agence.</p>"},{"location":"generic-architecture/#glossaire","title":"Glossaire","text":"<p>Kubernetes : Kubernetes est une plateforme open-source con\u00e7ue pour automatiser le d\u00e9ploiement, la mise \u00e0 l'\u00e9chelle et le fonctionnement des conteneurs d'applications. Elle regroupe les conteneurs qui composent une application en unit\u00e9s logiques pour une gestion et une d\u00e9couverte faciles. Kubernetes fournit des outils pour orchestrer des syst\u00e8mes distribu\u00e9s \u00e0 grande \u00e9chelle.</p> <p>Pod : Dans le contexte de Kubernetes, un Pod est la plus petite unit\u00e9 d\u00e9ployable qui peut \u00eatre cr\u00e9\u00e9e et g\u00e9r\u00e9e. Il repr\u00e9sente une instance unique d'un processus en cours d'ex\u00e9cution dans votre cluster et peut contenir un ou plusieurs conteneurs partageant le stockage, le r\u00e9seau, et une sp\u00e9cification sur la fa\u00e7on d'ex\u00e9cuter les conteneurs. Les Pods sont \u00e9ph\u00e9m\u00e8res par nature et peuvent \u00eatre remplac\u00e9s par Kubernetes en cas de d\u00e9faillance de n\u0153ud ou d'autres \u00e9v\u00e9nements.</p> <p>Ingress : Ingress fait r\u00e9f\u00e9rence \u00e0 l'acte d'entrer ou \u00e0 la capacit\u00e9 d'entrer. Dans le contexte des r\u00e9seaux et de l'informatique, cela d\u00e9signe g\u00e9n\u00e9ralement le trafic entrant vers un r\u00e9seau ou un service \u00e0 partir d'une source externe.</p> <p>Load balancer (\u00c9quilibreur de charge) : Un \u00e9quilibreur de charge est un syst\u00e8me qui distribue le trafic r\u00e9seau ou applicatif sur plusieurs serveurs pour assurer qu'aucun serveur ne soit surcharg\u00e9, am\u00e9liorant ainsi la fiabilit\u00e9 et les performances des applications. Il aide \u00e0 pr\u00e9venir la surcharge des serveurs, \u00e0 g\u00e9rer le basculement, et \u00e0 augmenter la disponibilit\u00e9 d'un site web ou d'un service en routant automatiquement les requ\u00eates des clients vers le serveur le plus appropri\u00e9.</p> <p>Haute disponibilit\u00e9 (HA) : La haute disponibilit\u00e9 (HA) fait r\u00e9f\u00e9rence \u00e0 des syst\u00e8mes con\u00e7us pour \u00eatre op\u00e9rationnels et accessibles sans interruption significative. Cela est r\u00e9alis\u00e9 gr\u00e2ce \u00e0 des m\u00e9canismes de redondance et de basculement, garantissant que si un composant \u00e9choue, un autre peut prendre le relais sans interruption du service. L'objectif de la HA est de minimiser les chances d'interruption de service due \u00e0 des pannes mat\u00e9rielles, \u00e0 la maintenance ou \u00e0 des pannes impr\u00e9vues.</p> <p>Azure : Azure est un service de cloud computing cr\u00e9\u00e9 par Microsoft pour construire, tester, d\u00e9ployer et g\u00e9rer des applications et des services via des centres de donn\u00e9es g\u00e9r\u00e9s par Microsoft. Il offre une gamme de services cloud, y compris ceux pour le calcul, l'analytique, le stockage et les r\u00e9seaux. Les utilisateurs peuvent choisir parmi ces services pour d\u00e9velopper et mettre \u00e0 l'\u00e9chelle de nouvelles applications ou ex\u00e9cuter des applications existantes dans le cloud public.</p> <p>Au Canada, Azure dispose de deux r\u00e9gions : Canada Central (CA) et Canada East (CE). Canada Central est situ\u00e9 \u00e0 Toronto et est con\u00e7u pour offrir une faible latence aux services financiers et autres entreprises de la r\u00e9gion. Canada East, situ\u00e9 \u00e0 Qu\u00e9bec, fournit un support en langue fran\u00e7aise et une reprise apr\u00e8s sinistre pour les entreprises qui n\u00e9cessitent la r\u00e9sidence des donn\u00e9es dans la province de Qu\u00e9bec.</p> <p>Virtual Network (VNet) : Un r\u00e9seau virtuel dans le cloud est un environnement r\u00e9seau simul\u00e9 qui offre une s\u00e9paration logique des ressources au sein d'une plateforme de cloud computing. Il permet aux utilisateurs de d\u00e9finir leur propre topologie de r\u00e9seau, g\u00e9rer les adresses IP, configurer des pare-feu, et de mettre en place des sous-r\u00e9seaux et des tables de routage, tout cela dans un espace s\u00e9curis\u00e9 et isol\u00e9 qui imite les fonctionnalit\u00e9s d'un r\u00e9seau traditionnel.</p>"},{"location":"generic-architecture/#diagrammes","title":"Diagrammes","text":"<p>D\u00e9crivez le fonctionnement de notre impl\u00e9mentation pour la haute disponibilit\u00e9 (HA) ainsi que la redondance des services au sein d'Azure en utilisant Kubernetes.</p> <pre><code>flowchart\n    subgraph Azure[\"Azure\"]\n        direction TB\n        subgraph CC[\"Canada central (CA)\"]\n            subgraph VNet1[\"VNet-CC\"]\n                subgraph Kubernetes1[\"Kubernetes-CC\"]\n                    direction TB\n                    Ingress1[\"Ingress\"]\n                    Pod1[\"Pod\"]\n                    Pod2[\"Pod\"]\n                    Pod3[\"Pod\"]\n                    Pod4[\"Pod\"]\n                    Pod5[\"Pod\"]\n                    Pod6[\"Pod\"]\n                end\n            end\n        end\n\n        subgraph CE[\"Canada east (CE)\"]\n            subgraph VNet2[\"VNet-CE\"]\n                subgraph Kubernetes2[\"Kubernetes-CE\"]\n                    direction TB\n                    Ingress2[\"Ingress\"]\n                    Pod7[\"Pod\"]\n                    Pod8[\"Pod\"]\n                    Pod9[\"Pod\"]\n                    Pod10[\"Pod\"]\n                    Pod11[\"Pod\"]\n                    Pod12[\"Pod\"]\n                end\n            end\n        end\n\n        VNet1[\"VNet-CC\"] &lt;---&gt;|HA| VNet2[\"VNet-CE\"]\n        Kubernetes1[\"Kubernetes-CC\"] &lt;---&gt;|1:1 redundancy| Kubernetes2[\"Kubernetes-CE\"]\n    end</code></pre> <p>Repr\u00e9sente le processus d'envoi d'une requ\u00eate \u00e0 notre infrastructure au sein d'Azure.</p> <pre><code>flowchart\n    Client[\"Client\"] --&gt;|request| LB\n    subgraph Azure[\"Azure\"]\n        LB[\"Load balancer\"]\n        LB --&gt; VNet1\n        LB --&gt; VNet2\n        direction LR\n        subgraph CC[\"Canada central (CC)\"]\n            subgraph VNet1[\"VNet-CC\"]\n                subgraph Kubernetes1[\"Kubernetes-CC\"]\n                    direction TB\n                    Ingress1[\"Ingress\"]\n                    Pod1[\"Pod\"]\n                    Pod2[\"Pod\"]\n                    Pod3[\"Pod\"]\n                    Pod4[\"Pod\"]\n                    Pod5[\"Pod\"]\n                    Pod6[\"Pod\"]\n                end\n            end\n        end\n\n        subgraph CE[\"Canada east (CE)\"]\n            subgraph VNet2[\"VNet-CE\"]\n                subgraph Kubernetes2[\"Kubernetes-CE\"]\n                    direction TB\n                    Ingress2[\"Ingress\"]\n                    Pod7[\"Pod\"]\n                    Pod8[\"Pod\"]\n                    Pod9[\"Pod\"]\n                    Pod10[\"Pod\"]\n                    Pod11[\"Pod\"]\n                    Pod12[\"Pod\"]\n                end\n            end\n        end\n    end</code></pre> <p>Repr\u00e9sentation des deux diagrammes ci-dessus en un seul.</p> <p></p>"},{"location":"generic-architecture/#references","title":"R\u00e9f\u00e9rences","text":"<p>Kubernetes</p> <p>Pod</p> <p>HA</p> <p>Load balancer</p>"},{"location":"gh_docker_workflow/","title":"Workflow GitHub pour construire et pousser des images vers ghcr","text":""},{"location":"gh_docker_workflow/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>Le texte fourni d\u00e9crit un workflow con\u00e7u pour construire et pousser une image vers le GitHub Container Registry. Il implique la cr\u00e9ation de trois tags : num\u00e9ro de pull request, nom de pull request, et commit SHA.</p>"},{"location":"gh_docker_workflow/#glossaire","title":"Glossaire","text":"<p>Image : Le terme \"image\" fait g\u00e9n\u00e9ralement r\u00e9f\u00e9rence \u00e0 un composant logiciel autonome et emball\u00e9 qui inclut tout ce qui est n\u00e9cessaire pour ex\u00e9cuter une application, comme le code, le runtime, les biblioth\u00e8ques et les d\u00e9pendances.</p> <p>GitHub Container Registry (GHCR) : GCR est un service fourni par GitHub qui permet aux utilisateurs de stocker, g\u00e9rer et distribuer des images de conteneurs Docker au sein de l'\u00e9cosyst\u00e8me GitHub. Il sert de r\u00e9f\u00e9rentiel centralis\u00e9 pour les images de conteneurs associ\u00e9es aux d\u00e9p\u00f4ts GitHub.</p> <p>GitHub Action : Une GitHub Action est essentiellement un workflow ou un processus automatis\u00e9 d\u00e9fini au sein d'un d\u00e9p\u00f4t GitHub. Elle permet aux utilisateurs d'automatiser des t\u00e2ches telles que la construction, le test et le d\u00e9ploiement de logiciels directement sur la plateforme GitHub, offrant ainsi un moyen puissant de rationaliser les workflows de d\u00e9veloppement.</p>"},{"location":"gh_docker_workflow/#explication-du-diagramme","title":"Explication du diagramme","text":"<p>Le diagramme illustre un workflow pour construire et pousser une image vers le GitHub Container Registry. Il d\u00e9crit les \u00e9tapes impliqu\u00e9es dans ce processus, y compris la cr\u00e9ation de trois tags sp\u00e9cifiques : num\u00e9ro de pull request, nom de pull request, et commit SHA bas\u00e9s sur le commit effectu\u00e9 dans une pull request. Une fois l'image dans le GCR, un d\u00e9ploiement Kubernetes peut utiliser cette image.</p>"},{"location":"gh_docker_workflow/#diagrammes","title":"Diagrammes","text":""},{"location":"gh_docker_workflow/#references","title":"R\u00e9f\u00e9rences","text":"<p>Docker</p> <p>Github action</p> <p>Github container registry</p> <p>Image Kubernetes</p>"},{"location":"multi-layered-application/","title":"Application \u00e0 niveaux multiples","text":""},{"location":"multi-layered-application/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>Dans notre architecture \u00e0 niveaux multiples, le frontend et le backend de nos applications sont intimement li\u00e9s, avec le backend cod\u00e9 en Python et le frontend en TypeScript, chacun r\u00e9sidant dans leurs r\u00e9pertoires respectifs. Le backend ne se contente pas de traiter les demandes, mais interagit \u00e9galement occasionnellement avec diverses solutions de stockage d'objets comme les mod\u00e8les d'IA, les bases de donn\u00e9es et le stockage blob pour g\u00e9rer et r\u00e9cup\u00e9rer des donn\u00e9es. Cette interaction est cruciale pour le fonctionnement transparent de nos services et est repr\u00e9sent\u00e9e dans les diagrammes de s\u00e9quence accompagnants, qui illustrent le flux d'une requ\u00eate depuis le frontend \u00e0 travers l'ingress jusqu'au backend.</p>"},{"location":"multi-layered-application/#glossaire","title":"Glossaire","text":"<p>Frontend : Le frontend se r\u00e9f\u00e8re \u00e0 la partie d'un site web ou d'une application avec laquelle les utilisateurs interagissent directement, englobant le design, la mise en page et le comportement que les gens exp\u00e9rimentent dans un navigateur web ou une interface d'application.</p> <p>Backend : Le backend fait r\u00e9f\u00e9rence au c\u00f4t\u00e9 serveur d'une application web, englobant la base de donn\u00e9es, le serveur et la logique d'application qui traitent les requ\u00eates des utilisateurs et r\u00e9alisent les op\u00e9rations fonctionnelles principales du syst\u00e8me.</p> <p>Base de donn\u00e9es : Une base de donn\u00e9es est une collection structur\u00e9e de donn\u00e9es stock\u00e9es et accessibles \u00e9lectroniquement, con\u00e7ue pour g\u00e9rer, interroger et r\u00e9cup\u00e9rer des informations de mani\u00e8re efficace.</p> <p>Ingress : Ingress fait r\u00e9f\u00e9rence \u00e0 l'acte d'entrer ou \u00e0 la capacit\u00e9 d'entrer. Dans le contexte des r\u00e9seaux et de l'informatique, cela d\u00e9signe g\u00e9n\u00e9ralement le trafic entrant vers un r\u00e9seau ou un service \u00e0 partir d'une source externe.</p> <p>Navigateur : Un navigateur, \u00e9galement connu sous le nom de navigateur web, est une application logicielle utilis\u00e9e pour acc\u00e9der, r\u00e9cup\u00e9rer et afficher du contenu sur le World Wide Web, y compris des pages web, des images, des vid\u00e9os et d'autres multim\u00e9dias. Il interpr\u00e8te le HTML et d'autres technologies web pour pr\u00e9senter l'information dans un format accessible.</p>"},{"location":"multi-layered-application/#diagrammes","title":"Diagrammes","text":"<p>Ce diagramme montre la communication entre le frontend, le backend (/api), le navigateur (client), et l'ingress (ingress nginx) pour une application.</p> <pre><code>sequenceDiagram\n    participant Browser\n    participant Ingress\n    participant Frontend\n    participant Backend\n\n    Note over Browser,Backend: DNS https://inspection.alpha.canada.ca resolves to Ingress IP with A record\n    Note over Browser,Backend: https://*.inspection.alpha.canada.ca * is any CNAME to the DNS\n\n    Browser-&gt;&gt;Ingress: GET / https://*.inspection.alpha.canada.ca\n    Ingress-&gt;&gt;Frontend: GET /\n    Frontend--&gt;&gt;Ingress: 200\n    Ingress--&gt;&gt;Browser: The browser display the result\n\n    Browser-&gt;&gt;Ingress: GET /api/search https://*.inspection.alpha.canada.ca/api/search/\n    Ingress-&gt;&gt;Backend: GET /search\n    Note over Ingress: /api is /search (ImplementationSpecific)\n    Backend--&gt;&gt;Ingress: 200\n    Ingress--&gt;&gt;Browser: The browser display the result</code></pre>"},{"location":"multi-layered-application/#references","title":"References","text":"<p>Ingress NGINX</p> <p>Ingress NGINX - ImplementationSpecific</p> <p>DNS</p> <p>DNS - A record</p> <p>DNS - CNAME record</p>"},{"location":"networking/","title":"R\u00e9seautique","text":""},{"location":"networking/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>Voici comment une requ\u00eate est rout\u00e9e vers notre cluster Kubernetes. Une fois que l'image r\u00e9pond avec le contenu, le processus est invers\u00e9 pour afficher les r\u00e9sultats \u00e0 l'utilisateur.</p>"},{"location":"networking/#glossaire","title":"Glossaire","text":"<p>DNS : Traduction des noms de domaine (comme google.com) en adresses IP (comme 172.217.14.238).</p> <p>Ingress NGINX : Un contr\u00f4leur qui utilise NGINX comme serveur web pour g\u00e9rer le trafic entrant vers un cluster Kubernetes. Il route le trafic vers diff\u00e9rents services en fonction de l'URL, du nom d'h\u00f4te ou d'autres crit\u00e8res.</p> <p>Kubernetes : Une plateforme d'orchestration de conteneurs open-source pour automatiser le d\u00e9ploiement, la mise \u00e0 l'\u00e9chelle et la gestion des applications conteneuris\u00e9es.</p> <p>Cert-manager : Un outil pour g\u00e9rer les certificats TLS pour Kubernetes. Il automatise le processus d'obtention, de renouvellement et de validation des certificats pour les services expos\u00e9s sur internet.</p>"},{"location":"networking/#diagrammes","title":"Diagrammes","text":""},{"location":"networking/#inspectionalphacanadaca","title":".inspection.alpha.canada.ca","text":"<p>Dans le cadre des d\u00e9ploiements que nous effectuons au sein du Laboratoire d'IA, nous avions besoin d'un DNS qui nous permettrait de d\u00e9ployer nos services. Puisque nous ne sommes pas en production, nous avions besoin d'un nom qui soit appropri\u00e9 pour un environnement alpha/staging et qui soit conforme aux directives suivantes :</p> <ul> <li>Alpha canada.ca</li> <li>Government of Canada Digital Standards</li> </ul> <p>Pour plus d'informations, veuillez vous r\u00e9f\u00e9rer \u00e0 cette pull request (PR) soumise \u00e0 cds-snc afin qu'ils puissent nous subd\u00e9l\u00e9guer <code>inspection.alpha.canada.ca</code> :</p> <ul> <li>The pull request made to cds-snc (status: merged)</li> </ul>"},{"location":"networking/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Cert manager</li> <li>Ingress NGINX</li> <li>DNS</li> <li>Kubernetes</li> </ul>"},{"location":"secrets-management/","title":"Gestion des secrets","text":""},{"location":"secrets-management/#introduction","title":"Introduction","text":"<p>Les secrets sont des informations sensibles qui doivent \u00eatre prot\u00e9g\u00e9es contre tout acc\u00e8s non autoris\u00e9. Dans le contexte d'un cluster Kubernetes, les secrets sont utilis\u00e9s pour stocker des donn\u00e9es sensibles telles que des mots de passe, des jetons et des cl\u00e9s. Pour permettre une gestion s\u00e9curis\u00e9e et efficace des secrets, nous utilisons HashiCorp Vault, un outil con\u00e7u pour g\u00e9rer les secrets et prot\u00e9ger les donn\u00e9es sensibles. Vault fournit un moyen centralis\u00e9 de g\u00e9rer l'acc\u00e8s aux secrets et aux cl\u00e9s de chiffrement, et il a \u00e9galement la capacit\u00e9 de g\u00e9n\u00e9rer des secrets dynamiques \u00e0 la demande. Ce document fournit un aper\u00e7u du processus de gestion des secrets et du r\u00f4le de Vault dans la s\u00e9curisation et la gestion des secrets dans le cluster Kubernetes.</p>"},{"location":"secrets-management/#architecture-de-vault","title":"Architecture de Vault","text":"<p>Vault est un syst\u00e8me hautement disponible et distribu\u00e9 con\u00e7u pour fournir un stockage s\u00e9curis\u00e9 et une gestion des secrets. Il est bas\u00e9 sur une architecture client-serveur, avec le serveur \u00e9tant le composant central qui stocke et g\u00e8re les secrets, et les clients \u00e9tant les applications et services qui acc\u00e8dent aux secrets. Le serveur est responsable de l'authentification des clients, de l'autorisation de l'acc\u00e8s aux secrets, et de la fourniture de services de chiffrement et de d\u00e9chiffrement. Le serveur est \u00e9galement responsable de g\u00e9n\u00e9rer des secrets dynamiques \u00e0 la demande, qui sont de courte dur\u00e9e et sont automatiquement r\u00e9voqu\u00e9s apr\u00e8s une certaine p\u00e9riode.</p> <p>La configuration actuelle permet \u00e0 Vault d'injecter des secrets dans les pods en utilisant le plugin ArgoCD Vault. Le plugin lit les espaces r\u00e9serv\u00e9s dans les fichiers YAML et les remplace par les valeurs r\u00e9elles des secrets provenant de Vault. Cela offre un moyen s\u00e9curis\u00e9 de g\u00e9rer les secrets dans le cluster Kubernetes et garantit que les donn\u00e9es sensibles sont prot\u00e9g\u00e9es contre tout acc\u00e8s non autoris\u00e9.</p> <p>Le diagramme suivant illustre la structure de l'architecture Vault au sein de Howard: </p> <p>Le diagramme de s\u00e9quence suivant d\u00e9crit le processus permettant \u00e0 un d\u00e9veloppeur de mettre \u00e0 jour des secrets en utilisant le service UI de Vault et comment les secrets sont inject\u00e9s dans les pods :</p> <pre><code>sequenceDiagram\n    participant Developer\n    participant FinesseRepo as Finesse Repository\n    participant GHWorkflow as GitHub Workflow\n    participant ContainerReg as GitHub Container Registry\n    participant HowardRepo as Howard Repository\n    participant ArgoRepoServer as ArgoCD Repo Server\n    participant ArgoVaultPlugin as Argo Vault Plugin\n    participant FinessePod as Finesse Pod\n\n    participant VaultUI as Vault UI\n    participant Vault as Vault Server\n\n    Developer-&gt;&gt;+FinesseRepo: 1. Pushes commits\n    FinesseRepo-&gt;&gt;+GHWorkflow: Triggers workflow\n    GHWorkflow-&gt;&gt;+ContainerReg: Builds and pushes new semantic version\n    GHWorkflow-&gt;&gt;+ArgoRepoServer: Triggers webhook\n    ArgoRepoServer-&gt;&gt;+FinessePod: Triggers synchronisation to pod\n    FinessePod-&gt;&gt;+ContainerReg: Fetches image with new version tag\n    FinessePod-&gt;&gt;+FinessePod: Refreshes deployment with new version\n    Developer-&gt;&gt;+VaultUI: 2. Accesses UI to update/create secrets\n    VaultUI-&gt;&gt;+Vault: Commit update/creation of secrets\n    Developer-&gt;&gt;+HowardRepo: 3. Commits new/updated secrets\n    HowardRepo-&gt;&gt;+ArgoRepoServer: Triggers sync via webhook\n    ArgoRepoServer-&gt;&gt;+ArgoVaultPlugin: triggers refresh on finesse namespace,&lt;br&gt; sync secrets from Vault\n    ArgoVaultPlugin-&gt;&gt;+Vault: Fetch specific version of secrets\n    ArgoVaultPlugin-&gt;&gt;+FinessePod: Injects secrets\n    Developer-&gt;&gt;+FinessePod: 4. Trigger hard refresh through argoCD</code></pre> <p>Veuillez noter que le d\u00e9veloppeur doit d\u00e9clencher un rafra\u00eechissement complet du pod pour refl\u00e9ter les modifications des secrets. Cela se fait dans l'interface utilisateur d'ArgoCD, mais nous travaillons sur un moyen d'automatiser ce processus.</p>"},{"location":"secrets-management/#processus-de-gestion-des-secrets","title":"Processus de gestion des secrets","text":"<p>The secret management process involves the following steps:</p> <ol> <li> <p>Cr\u00e9ation des secrets: Les secrets sont cr\u00e9\u00e9s et stock\u00e9s dans Vault en     utilisant l'interface CLI de Vault ou  l'API. Lorsqu'un secret est cr\u00e9\u00e9,     il est chiffr\u00e9 et stock\u00e9 dans le serveur central Vault.</p> </li> <li> <p>R\u00e9cup\u00e9ration des secrets: Les applications et services peuvent r\u00e9cup\u00e9rer les     secrets depuis Vault en utilisant l'interface CLI de Vault ou l'API.     Lorsqu'un secret est r\u00e9cup\u00e9r\u00e9, il est d\u00e9chiffr\u00e9 et renvoy\u00e9 au client     de mani\u00e8re s\u00e9curis\u00e9e.</p> </li> <li> <p>G\u00e9n\u00e9ration de secrets dynamiques: Vault has the ability to generate     dynamic secrets on demand. This means that instead of     storing static secrets in Vault, Vault can generate short-lived secrets     that are automatically revoked after a certain period of time. This     provides an additional layer of security and reduces the risk of     unauthorized access to secrets.</p> </li> <li> <p>Contr\u00f4le d'acc\u00e8s: Vault fournit un contr\u00f4le d'acc\u00e8s granulaire     aux secrets, permettant aux administrateurs de d\u00e9finir des politiques     qui sp\u00e9cifient quels clients peuvent acc\u00e9der \u00e0 quels secrets. Cela     garantit que seuls les clients autoris\u00e9s peuvent acc\u00e9der aux donn\u00e9es     sensibles. Actuellement, nous utilisons la m\u00e9thode d\u2019authentification     Kubernetes pour authentifier les applications h\u00e9berg\u00e9es et autoriser     l'acc\u00e8s aux secrets. En ce qui concerne les utilisateurs humains,     nous utilisons la m\u00e9thode d'authentification GitHub pour     authentifier et autoriser l'acc\u00e8s aux secrets.</p> </li> </ol>"},{"location":"secrets-management/#creation-lecture-mise-a-jour-et-suppression-des-secrets","title":"Cr\u00e9ation, lecture, mise \u00e0 jour et suppression des secrets","text":"<p>Vault fournit un service d'interface utilisateur pour g\u00e9rer les secrets. Le service d'interface utilisateur est une interface utilisateur web qui permet aux administrateurs de cr\u00e9er, lire, mettre \u00e0 jour et supprimer des secrets. Le service fournit \u00e9galement un moyen de g\u00e9rer les politiques de contr\u00f4le d'acc\u00e8s et les journaux d'audit. Le service est accessible via un navigateur web et est prot\u00e9g\u00e9 par les m\u00eames m\u00e9canismes de s\u00e9curit\u00e9 que le serveur Vault.</p>"},{"location":"secrets-management/#etapes-pour-mettre-a-jour-les-valeurs-des-secrets-en-utilisant-linterface-utilisateur-de-vault","title":"\u00c9tapes pour mettre \u00e0 jour les valeurs des secrets en utilisant l'interface utilisateur de Vault","text":"<ol> <li>Afin d'acc\u00e9der au service d'interface utilisateur de Vault, vous devez    disposer des autorisations appropri\u00e9es et acc\u00e9der \u00e0 l'URL de Vault.    Elle est actuellement configur\u00e9e pour donner acc\u00e8s \u00e0 tout membre de    l'organisation ai-cfia sur Github.</li> <li>G\u00e9n\u00e9rez un jeton d'acc\u00e8s personnel (PAT) sur GitHub et utilisez-le    pour vous authentifier au service d'interface utilisateur de    Vault. La port\u00e9e du jeton devrait \u00eatre: </li> <li>Acc\u00e9dez au service d'interface utilisateur de Vault en naviguant vers l'URL    de Vault dans un navigateur web. Vous serez invit\u00e9 \u00e0 vous authentifier en    utilisant votre jeton PAT de GitHub.</li> <li>Une fois authentifi\u00e9, vous pourrez cr\u00e9er, lire, mettre \u00e0 jour et    supprimer des secrets en utilisant le service d'interface utilisateur.    Il vous suffit de naviguer vers le moteur de secrets PV et de suivre le    chemin jusqu'aux secrets de vos applications. Le moteur de secrets PV est    un magasin cl\u00e9-valeur qui vous permet de stocker et de g\u00e9rer les secrets    pour vos applications.</li> <li>Une fois dans le r\u00e9pertoire des secrets de votre application, cliquez    simplement sur 'create new version' (cr\u00e9er une nouvelle version) et vous    pourrez ajouter, mettre \u00e0 jour ou supprimer des secrets selon    vos besoins.</li> </ol>"},{"location":"secrets-management/#etapes-pour-mettre-a-jour-les-secrets-injectes-dans-les-pods","title":"\u00c9tapes pour mettre \u00e0 jour les secrets inject\u00e9s dans les pods","text":"<p>Pour mettre \u00e0 jour les secrets qui sont inject\u00e9s dans les pods, vous devez mettre \u00e0 jour le manifeste des secrets pour l'application. Le manifeste des secrets est un fichier YAML qui d\u00e9finit les secrets qui sont inject\u00e9s dans les pods en tant que variables d'environnement. Nous prendrons Finesse comme exemple.</p> <ol> <li>Ouvrez une issue avec le mod\u00e8le suivant : Mod\u00e8le de mise \u00e0 jour des    secrets. Vous pouvez ensuite    cr\u00e9er une branche de travail \u00e0 partir de l'issue.</li> <li>Ouvrir <code>/kubernetes/aks/apps/finesse/base/finesse-secrets.yaml</code>.</li> <li>Mettez \u00e0 jour les r\u00e9f\u00e9rences des cl\u00e9s de secrets selon les besoins.    Par exemple, pour ajouter un nouveau secret, vous pouvez ajouter une    nouvelle paire cl\u00e9-valeur \u00e0 la section data du manifeste des secrets :</li> </ol> <pre><code>FINESSE_BACKEND_AZURE_SEARCH_TRANSFORM_MAP: &lt;FINESSE_BACKEND_AZURE_SEARCH_TRANSFORM_MAP&gt;\n</code></pre> <p>La cl\u00e9 repr\u00e9sente le nom de la variable d'environnement qui sera inject\u00e9e    dans le pod, et la valeur repr\u00e9sente la cl\u00e9 du secret dans Vault qui sera    utilis\u00e9e pour r\u00e9cup\u00e9rer la valeur du secret.</p> <ol> <li>Mettez \u00e0 jour l'annotation de version des secrets r\u00e9cup\u00e9r\u00e9s depuis Vault :</li> </ol> <pre><code># Augmentez la version du secret de\navp.kubernetes.io/secret-version: \"4\"\n# \u00c0\navp.kubernetes.io/secret-version: \"5\"\n</code></pre> <p>Ceci est la nouvelle version que nous cr\u00e9ons \u00e0 l'\u00e9tape 5 de la section    pr\u00e9c\u00e9dente.</p> <p>\u00c0 titre d'exemple suppl\u00e9mentaire, voici un probl\u00e8me et une pull request    qui illustrent le processus de mise \u00e0 jour des secrets dans    l'application Nachet :</p> <ul> <li>Issue</li> <li>Pull request</li> </ul>"},{"location":"secrets-management/#plugin-argo-cd-vault-avp","title":"Plugin Argo CD Vault (AVP)","text":"<p>Le argocd-vault-plugin est utilis\u00e9 pour g\u00e9rer les secrets au sein de nos d\u00e9ploiements de mani\u00e8re GitOps. Il permet d'utiliser des <code>&lt;placeholders&gt;</code> dans n'importe quel fichier YAML ou JSON qui a \u00e9t\u00e9 mod\u00e9lis\u00e9 et fait usage d'annotations pour fournir le chemin et la version d'un secret dans le Vault.</p> <p>Un exemple d'utilisation est pr\u00e9sent\u00e9 dans l'application de d\u00e9monstration. La documentation du plugin est bien expliqu\u00e9e et peut \u00eatre suivie en fonction du cas d'utilisation n\u00e9cessaire.</p>"},{"location":"terraform-workflow/","title":"Workflow Terraform pour la gestion des ressources dans Azure","text":"<p>Cette section sert de guide pour utiliser le pipeline Azure DevOps configur\u00e9 dans le d\u00e9p\u00f4t 'AI-Lab', qui est con\u00e7u pour g\u00e9rer les d\u00e9ploiements d'infrastructure via Terraform au sein de notre organisation. Le code du pipeline r\u00e9side actuellement sur GitHub, car c'est l\u00e0 que se trouve le code d'infrastructure. Il est actuellement configur\u00e9 avec Azure DevOps car c'est le seul moyen d'avoir acc\u00e8s \u00e0 un service account nous permettant de cr\u00e9er des ressources sur notre abonnement Azure.</p> <p>Le diagramme suivant illustre le workflow Terraform pour la gestion des ressources : </p>"},{"location":"terraform-workflow/#demarrage","title":"D\u00e9marrage","text":"<ul> <li> <p>Pr\u00e9requis : Assurez-vous d'avoir les acc\u00e8s n\u00e9cessaires au projet Azure DevOps et au d\u00e9p\u00f4t 'AI-Lab'.</p> </li> <li> <p>Configuration du R\u00e9f\u00e9rentiel : Le pipeline apply-terraform.yml est li\u00e9 \u00e0 Azure DevOps via un connecteur de service.</p> </li> </ul>"},{"location":"terraform-workflow/#flux-du-processus-dapprobation","title":"Flux du processus d'approbation","text":"<p>Le pipeline inclut une \u00e9tape d'approbation essentielle avant d'appliquer tout plan Terraform pour garantir que tous les changements sont examin\u00e9s et autoris\u00e9s. Cette \u00e9tape est cruciale pour maintenir le contr\u00f4le sur les modifications de l'infrastructure et s'assurer qu'elles r\u00e9pondent \u00e0 nos normes op\u00e9rationnelles et de s\u00e9curit\u00e9.</p>"},{"location":"terraform-workflow/#environnement-dapprobation-de-la-production","title":"Environnement d'approbation de la production","text":"<ul> <li> <p>L'environnement <code>ProductionApproval</code> dans Azure DevOps est configur\u00e9 pour n\u00e9cessiter une approbation manuelle avant que l'\u00e9tape d'application de Terraform puisse se poursuivre.</p> </li> <li> <p>Cet environnement est li\u00e9 \u00e0 notre abonnement Azure via une connexion de service, qui dispose des autorisations n\u00e9cessaires pour appliquer un plan Terraform.</p> </li> </ul>"},{"location":"terraform-workflow/#comment-approuver-les-changements","title":"Comment approuver les changements","text":"<ol> <li> <p>Examen du Plan : Lorsqu'un plan Terraform est d\u00e9clench\u00e9 par un commit sur la branche <code>main</code>, il initialise d'abord et planifie les modifications de l'infrastructure sans les appliquer.</p> </li> <li> <p>Notification d'Approbation : Les parties prenantes concern\u00e9es recevront une notification (par email ou dans Azure DevOps) demandant l'approbation des modifications planifi\u00e9es.</p> </li> <li> <p>Acc\u00e9der \u00e0 la Demande d'Approbation : Naviguez vers la section <code>Environments</code> dans le projet Azure DevOps et s\u00e9lectionnez l'environnement <code>ProductionApproval</code> pour voir les approbations en attente.</p> </li> <li> <p>Analyse et Approbation : Examinez les d\u00e9tails des modifications planifi\u00e9es. Si elles sont conformes \u00e0 nos normes et attentes, approuvez le d\u00e9ploiement. Sinon, vous pouvez rejeter ou discuter des modifications avec l'\u00e9quipe.</p> </li> </ol>"},{"location":"adr/010-infrastructure.fr-ca/","title":"ADR-010 : Infrastructure","text":""},{"location":"adr/010-infrastructure.fr-ca/#resume-executif","title":"R\u00e9sum\u00e9 Ex\u00e9cutif","text":"<p>Dans un effort d'optimisation et de s\u00e9curisation de nos op\u00e9rations d'infrastructure, notre organisation a adopt\u00e9 une strat\u00e9gie bas\u00e9e sur l'Infrastructure as Code (IaC) en utilisant Terraform, accompagn\u00e9e par le d\u00e9ploiement d'un cluster Kubernetes sur Azure. Cette approche nous permet de surmonter les limitations associ\u00e9es aux m\u00e9thodes traditionnelles telles que ClickOps et les d\u00e9ploiements manuels, qui \u00e9taient \u00e0 la fois chronophages et susceptibles d'erreur. L'adoption de HashiCorp Vault pour la gestion centralis\u00e9e des secrets et d'ArgoCD pour l'orchestration des d\u00e9ploiements renforce notre posture de s\u00e9curit\u00e9 et d'agilit\u00e9. En int\u00e9grant des solutions de monitoring avanc\u00e9es et en envisageant l'utilisation de technologies comme OpenTelemetry pour une observabilit\u00e9 accrue, nous visons \u00e0 maintenir une haute disponibilit\u00e9 et performance de nos services. Cette transformation permet une gestion plus robuste et automatis\u00e9e de l'infrastructure, r\u00e9duit les risques d'erreur humaine et offre une flexibilit\u00e9 et une portabilit\u00e9 accrues \u00e0 travers diff\u00e9rents environnements cloud. Notre initiative aligne la gestion des infrastructures avec nos objectifs op\u00e9rationnels tout en assurant une \u00e9volutivit\u00e9 et une s\u00e9curit\u00e9 renforc\u00e9es pour r\u00e9pondre aux besoins futurs.</p>"},{"location":"adr/010-infrastructure.fr-ca/#contexte","title":"Contexte","text":"<p>Notre \u00e9quipe fait face \u00e0 des d\u00e9fis en mati\u00e8re de d\u00e9ploiement de solutions, notamment dans le choix des fournisseurs d'infonuages. Initialement, nous utilisions Google Cloud Run et Azure App Service. Cependant, en raison de l'absence de compte Google Cloud et des restrictions d'acc\u00e8s sur Azure, nous nous retrouvons \u00e0 basculer d'un compte \u00e0 l'autre, entra\u00eenant d'importants temps d'arr\u00eat pour nos applications.</p> <p>De plus, la cr\u00e9ation manuelle de tous les services sur les fournisseurs de cloud via le ClickOps s'est av\u00e9r\u00e9e fastidieuse. Pour surmonter ce d\u00e9fi, , nous avons d\u00e9cid\u00e9 d'adopter l'Infrastructure as Code (IaC) en utilisant Terraform. Cette approche nous permet de g\u00e9rer et de provisionner nos infrastructures cloud via des fichiers de configuration codifi\u00e9s, \u00e9liminant ainsi le besoin de ClickOps et r\u00e9duisant significativement les erreurs humaines.</p> <p>En ce qui concerne la s\u00e9curit\u00e9, nous avions initialement adopt\u00e9 Azure Key Vault  pour la r\u00e9cup\u00e9ration manuelle des valeurs des variables d'environnement. Cependant, reconnaissant la n\u00e9cessit\u00e9 d'une solution plus robuste et polyvalente pour la gestion des secrets, nous avons \u00e9volu\u00e9 vers le maintien d'une instance de HashiCorp Vault. Cette transition permet une gestion centralis\u00e9e des secrets et des identifiants \u00e0 travers diff\u00e9rents environnements et plateformes.</p> <p>La mise \u00e0 l'echelle de nos applications n'est pas actuellement une priorit\u00e9, car nous avons une visibilit\u00e9 fixe sur le nombre d'utilisateurs. Cependant, nous n'avons pas encore mis en oeuvre de solution de mise \u00e0 l'\u00e9chelle.</p> <p>Actuellement, pour le monitoring et la t\u00e9l\u00e9m\u00e9trie, nous nous appuyons exclusivement sur les outils int\u00e9gr\u00e9s des fournisseurs de cloud, comme ceux de Google Cloud Run. Cependant, il est important de consid\u00e9rer la flexibilit\u00e9 et la portabilit\u00e9 que peuvent offrir des services externes tels qu'OpenTelemetry. Ces solutions peuvent non seulement s'adapter \u00e0 divers environnements de cloud mais aussi offrir une personnalisation pouss\u00e9e qui r\u00e9pond sp\u00e9cifiquement \u00e0 nos besoins. Bien que les solutions maison puissent sembler exigeantes en termes de maintenance, elles nous permettent d'optimiser notre surveillance et notre t\u00e9l\u00e9m\u00e9trie de mani\u00e8re cibl\u00e9e, offrant ainsi un potentiel d'alignement plus pr\u00e9cis avec nos objectifs op\u00e9rationnels.</p> <p>Bref, de nombreuses t\u00e2ches sont actuellement effectu\u00e9es manuellement. Bien que nous disposions de Github Workflow pour d\u00e9ployer des images Docker, la gestion des d\u00e9ploiements sur diff\u00e9rents fournisseurs d'infonuages n'est pas automatis\u00e9e. En cas d'erreur en production, aucune solution ne permet aux d\u00e9veloppeurs de r\u00e9soudre rapidement le probl\u00e8me</p>"},{"location":"adr/010-infrastructure.fr-ca/#cas-dutilisation","title":"Cas d'utilisation","text":"<ul> <li>G\u00e9rer la base de donn\u00e9es PostgreSQL (et bient\u00f4t PostgreSQL ML) sans recourir   au ClickOps.</li> <li>Accro\u00eetre la redondance des donn\u00e9es de mani\u00e8re plus efficace.</li> <li>D\u00e9ployer, g\u00e9rer, surveiller et instrumenter les applications au sein de   l'organisation.</li> <li>Am\u00e9liorer la gestion des secrets.</li> <li>\u00c9liminer les silos entre l'\u00e9quipe de s\u00e9curit\u00e9 et l'\u00e9quipe DevOps au sein de   l'organisation</li> <li>Mettre en place des d\u00e9ploiements sur tous les fournisseurs de cloud en cas de   pannes. Cela inclue une persistences des donn\u00e9es dans les diff\u00e9rents   fournisseurs d'infonuages.</li> <li>G\u00e9rer une solution SSO centralis\u00e9 pour authentifier les utilisateurs des   services h\u00e9berg\u00e9s.</li> <li>Utiliser l'Infrastructure as Code pour automatiser la cr\u00e9ation, le   d\u00e9ploiement, et la gestion de l'infrastructure permettant la rapidit\u00e9 des   op\u00e9rations d'infrastructure tout en r\u00e9duisant les erreurs manuelles.</li> <li>Automatisation de la mise \u00e0 l'\u00e9chelle (HPA).</li> <li>Adopter une strat\u00e9gie de sauvegarde et de reprise apr\u00e8s sinistre.</li> <li>Cr\u00e9er une documentation facile de lecture et d'adaption pour permettre une   transition \"shift-left\" (Int\u00e9gration anticip\u00e9e et approfondie des tests, de la   s\u00e9curit\u00e9 et de l'assurance qualit\u00e9 au d\u00e9but du cycle de d\u00e9veloppement   logiciel, pour une identification et r\u00e9solution plus pr\u00e9coces des anomalies).</li> <li>\u00c9viter les points de d\u00e9faillance uniques.</li> </ul>"},{"location":"adr/010-infrastructure.fr-ca/#decision","title":"D\u00e9cision","text":"<p>Notre solution consistera \u00e0 d\u00e9ployer des clusters Kubernetes sur diff\u00e9rents fournisseurs de cloud. Voici les composants qui seront d\u00e9ploy\u00e9s pour g\u00e9rer divers cas d'utilisation</p> <ul> <li>Gestion des conteneurs et leur d\u00e9ploiement:   Kubernetes</li> <li>Gestion des secrets: HashiCorp Vault</li> <li>Gestion des deployments: ArgoCD</li> <li>Gestion de l'Infrastructure as Code (IaC): Terraform</li> <li>Gestion des environnements de d\u00e9veloppement: AzureML (\u00e0 venir)</li> <li>Gestion d'authentification des utilisateurs:   Vouch-proxy</li> <li>Gestion de l'observabilit\u00e9: Grafana, Prometheus, Open-Telemetry et OneUptime   (\u00c0 venir)</li> <li>Gestion du load balancing: Ingress NGINX</li> <li>Gestion de la securit\u00e9: Trivy et Falco</li> <li>Gestion de la redondance: Istio / Cluster mesh (\u00e0 venir)</li> </ul> <p>D'autres composants seront ajout\u00e9s au besoin.</p>"},{"location":"adr/010-infrastructure.fr-ca/#consequences","title":"Cons\u00e9quences","text":"<p>La transition vers une gestion d'infrastructure bas\u00e9e sur Kubernetes et Terraform, combin\u00e9e \u00e0 l'utilisation de solutions robustes pour la gestion des secrets (HashiCorp Vault) et des d\u00e9ploiements (ArgoCD), marque un progr\u00e8s significatif vers une automatisation compl\u00e8te et une s\u00e9curisation accrue de notre environnement cloud.</p> <p>Cette approche permet de minimiser les interventions manuelles et les risques d'erreur, tout en renfor\u00e7ant la s\u00e9curit\u00e9 \u00e0 chaque \u00e9tape du d\u00e9ploiement des applications. En utilisant des outils open source, nous favorisons une plus grande transparence, une adaptabilit\u00e9 aux environnements multiples et une int\u00e9gration plus ais\u00e9e avec divers \u00e9cosyst\u00e8mes. De plus, l'adoption de pratiques GitOps, notamment \u00e0 travers Terraform et ArgoCD, am\u00e9liore la tra\u00e7abilit\u00e9 et la r\u00e9versibilit\u00e9 des changements apport\u00e9s \u00e0 l'infrastructure, essentielles pour la gestion des configurations et la conformit\u00e9 s\u00e9curitaire. Ces changements soutiennent notre capacit\u00e9 \u00e0 \u00e9voluer rapidement et de mani\u00e8re fiable, tout en maintenant un contr\u00f4le rigoureux sur la s\u00e9curit\u00e9 des donn\u00e9es et l'authentification des utilisateurs \u00e0 travers Vouch-proxy et l'int\u00e9gration de solutions telles que NGINX Ingress pour la gestion de l'acc\u00e8s. Cependant, cette \u00e9volution n\u00e9cessite une mont\u00e9e en comp\u00e9tence continue de nos \u00e9quipes et une attention soutenue aux mises \u00e0 jour et \u00e0 l'entretien de ces technologies pour garantir leur efficacit\u00e9 et leur s\u00e9curit\u00e9 \u00e0 long terme.</p>"},{"location":"adr/010-infrastructure.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Repertoire Howard - Contient la configuration de notre infrastructure   accompagn\u00e9e de documentation</li> </ul>"},{"location":"adr/011-gitops.fr-ca/","title":"ADR-011 : GitOps","text":""},{"location":"adr/011-gitops.fr-ca/#introduction","title":"Introduction","text":"<p>Ce document pr\u00e9sente la d\u00e9cision d'utiliser ArgoCD comme outil de d\u00e9ploiement continu pour nos applications Kubernetes.</p>"},{"location":"adr/011-gitops.fr-ca/#contexte","title":"Contexte","text":"<p>Avant l'impl\u00e9mentation d'ArgoCD, le processus de r\u00e9solution des probl\u00e8mes de production \u00e9tait manuel et chronophage. Un d\u00e9veloppeur devait remonter un probl\u00e8me \u00e0 un DevSecOps, ce qui pouvait entra\u00eener un d\u00e9lai d'attente avant la r\u00e9solution du probl\u00e8me.</p>"},{"location":"adr/011-gitops.fr-ca/#cas-dutilisation","title":"Cas d'utilisation","text":"<ul> <li> <p>Les d\u00e9veloppeurs peuvent d\u00e9ployer et tester leurs modifications sans avoir \u00e0 attendre l'intervention d'un DevSecOps.</p> </li> <li> <p>Les d\u00e9veloppeurs peuvent identifier et r\u00e9soudre les probl\u00e8mes de production plus rapidement.</p> </li> <li> <p>Les \u00e9quipes de d\u00e9veloppement et d'op\u00e9rations peuvent travailler plus \u00e9troitement ensemble.</p> </li> </ul>"},{"location":"adr/011-gitops.fr-ca/#decision","title":"D\u00e9cision","text":"<p>L'\u00e9quipe a d\u00e9j\u00e0 une exp\u00e9rience positive avec ArgoCD.</p>"},{"location":"adr/011-gitops.fr-ca/#alternatives-considerees","title":"Alternatives Consid\u00e9r\u00e9es","text":""},{"location":"adr/011-gitops.fr-ca/#flux","title":"Flux","text":"<p>Avantages:</p> <ul> <li>Facile \u00e0 configurer</li> </ul> <p>Inconv\u00e9nients:</p> <ul> <li>Absence d'interface utilisateur</li> </ul>"},{"location":"adr/011-gitops.fr-ca/#consequences","title":"Cons\u00e9quences","text":"<ul> <li> <p>Les d\u00e9veloppeurs pourront d\u00e9ployer et tester leurs modifications plus rapidement.</p> </li> <li> <p>Les probl\u00e8mes de production pourront \u00eatre r\u00e9solus  plus rapidement.</p> </li> <li> <p>Les \u00e9quipes de d\u00e9veloppement et d'op\u00e9rations pourront travailler plus \u00e9troitement ensemble.</p> </li> </ul>"},{"location":"adr/011-gitops.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>ArgoCD ACIA/CFIA url</li> <li>Document sur la gestion des secrets</li> </ul>"},{"location":"adr/012-secret-management.fr-ca/","title":"ADR-012 : Gestion des secrets","text":""},{"location":"adr/012-secret-management.fr-ca/#resume-executif","title":"R\u00e9sum\u00e9 Ex\u00e9cutif","text":"<p>Apr\u00e8s une analyse approfondie des options disponibles pour la gestion des secrets, nous avons d\u00e9cid\u00e9 d'adopter HashiCorp Vault. Cette solution se distingue par sa forte int\u00e9gration avec Kubernetes, sa capacit\u00e9 \u00e0 g\u00e9rer les secrets au sein des applications, son int\u00e9gration avec ArgoCD, et sa m\u00e9thode s\u00e9curis\u00e9e de partage des secrets. Ces caract\u00e9ristiques alignent Vault avec nos objectifs d'agilit\u00e9, de s\u00e9curit\u00e9, et d'efficacit\u00e9 dans la gestion des secrets pour nos services h\u00e9berg\u00e9s.</p>"},{"location":"adr/012-secret-management.fr-ca/#contexte","title":"Contexte","text":"<p>La gestion s\u00e9curis\u00e9e des secrets est cruciale pour la protection des informations sensibles et la s\u00e9curisation de notre infrastructure. Dans notre environnement, o\u00f9 Kubernetes joue un r\u00f4le central dans la gestion des services h\u00e9berg\u00e9s, il est essentiel de choisir une solution de gestion des secrets qui s'int\u00e8gre bien avec cet \u00e9cosyst\u00e8me, tout en offrant flexibilit\u00e9 et s\u00e9curit\u00e9. De plus, notre utilisation d'ArgoCD pour l'automatisation du d\u00e9ploiement exige que notre solution de gestion des secrets puisse s'int\u00e9grer sans heurt, facilitant une gestion coh\u00e9rente et s\u00e9curis\u00e9e des secrets \u00e0 travers nos pipelines CI/CD.</p>"},{"location":"adr/012-secret-management.fr-ca/#decision","title":"D\u00e9cision","text":"<p>Nous avons choisi HashiCorp Vault comme notre solution principale pour la gestion des secrets. Vault offre une int\u00e9gration \u00e9troite avec Kubernetes, permettant une gestion efficace des secrets au sein des applications. Cette int\u00e9gration se manifeste par le Vault Kubernetes Auth Method, qui autorise les applications tournant dans Kubernetes \u00e0 acc\u00e9der aux secrets stock\u00e9s dans Vault en utilisant les jetons de service Kubernetes pour l'authentification.</p> <p>Vault facilite \u00e9galement la rotation dynamique des secrets, garantissant que les informations sensibles ne restent pas statiques et sont r\u00e9guli\u00e8rement actualis\u00e9es sans intervention manuelle. Cette caract\u00e9ristique est essentielle pour maintenir une posture de s\u00e9curit\u00e9 \u00e9lev\u00e9e et r\u00e9duire la surface d'attaque potentielle li\u00e9e \u00e0 des secrets compromis.</p> <p>En outre, Vault peut g\u00e9n\u00e9rer des secrets \u00e0 la demande pour les bases de donn\u00e9es et d'autres services, ce qui r\u00e9duit le besoin de stocker des secrets statiques et augmente l'efficacit\u00e9 de la gestion des secrets. L'int\u00e9gration de Vault avec ArgoCD \u00e0 travers des plugins comme le Argo CD Vault Plugin simplifie le d\u00e9ploiement des applications en s'assurant que les secrets n\u00e9cessaires sont inject\u00e9s au moment du d\u00e9ploiement de mani\u00e8re s\u00e9curis\u00e9e.</p> <p>Choisir une instance centralis\u00e9e et auto-h\u00e9berg\u00e9e de Vault donne un contr\u00f4le total sur la gestion des secrets et assure une conformit\u00e9 avec les exigences de souverainet\u00e9 des donn\u00e9es, en permettant de stocker et g\u00e9rer les secrets au sein de notre propre infrastructure sans d\u00e9pendre de tiers.</p> <p>L'adoption de Vault facilite \u00e9galement l'impl\u00e9mentation de pratiques GitOps pour la gestion des configurations et des secrets, en assurant que toutes les modifications sont tra\u00e7ables, r\u00e9visables et d\u00e9ploy\u00e9es \u00e0 travers des processus d'int\u00e9gration et de d\u00e9ploiement continus.</p>"},{"location":"adr/012-secret-management.fr-ca/#alternatives-considerees","title":"Alternatives Consid\u00e9r\u00e9es","text":""},{"location":"adr/012-secret-management.fr-ca/#azure-key-vault","title":"Azure Key Vault","text":"<p>Avantages :</p> <ul> <li>Int\u00e9gration native avec l'\u00e9cosyst\u00e8me Azure, facilitant la gestion des secrets   pour les ressources Azure.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li> <p>Limit\u00e9 principalement \u00e0 l'\u00e9cosyst\u00e8me Azure, pr\u00e9sentant des d\u00e9fis pour les   d\u00e9ploiements multi-cloud ou hybrides.</p> </li> <li> <p>Moins d'int\u00e9gration native avec Kubernetes compar\u00e9 \u00e0 HashiCorp Vault, ce qui   pourrait complexifier la gestion des secrets dans nos applications Kubernetes.</p> </li> <li> <p>Azure Key Vault ne peut pas \u00eatre auto-h\u00e9berg\u00e9, ce qui peut poser des probl\u00e8mes   de souverainet\u00e9 des donn\u00e9es et de conformit\u00e9.</p> </li> <li> <p>Le Github action pour Azure Key Vault est obsol\u00e8te et n'est plus maintenu. La   seule facon d'obtenir des secrets d'Azure Key Vault dans un pipeline est   d'utiliser un script personnalis\u00e9. Ceci est expliquer dans leur repertoire   archiv\u00e9.</p> </li> <li> <p>Azure Key Vault ne supporte pas le versionnement des secrets et ne permet pas   de g\u00e9rer les secrets de mani\u00e8re GitOps.</p> </li> </ul>"},{"location":"adr/012-secret-management.fr-ca/#mozilla-sops","title":"Mozilla SOPS","text":"<p>Avantages :</p> <ul> <li>SOPS est un outil de gestion de secrets qui permet de chiffrer/d\u00e9chiffrer le   contenu d'un fichier avec une cl\u00e9 d\u00e9riv\u00e9e d'AWS, KMS, GCP KMS, Azure Key Vault   ou PGP, garantissant que les secrets sont toujours chiffr\u00e9s et peuvent \u00eatre   facilement int\u00e9gr\u00e9s dans les syst\u00e8mes de contr\u00f4le de version.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>SOPS n'est pas une solution de gestion de secrets qui remplit tous nos besoin   de facon autonome. Il ne g\u00e8re pas le stockage de secret dans un endroit   centralis\u00e9, ni la rotation des secrets.</li> </ul>"},{"location":"adr/012-secret-management.fr-ca/#consequences","title":"Cons\u00e9quences","text":"<p>L'adoption de HashiCorp Vault nous permettra de renforcer la s\u00e9curit\u00e9 de notre infrastructure en centralisant la gestion des secrets dans un outil con\u00e7u sp\u00e9cifiquement pour cela. L'int\u00e9gration avec Kubernetes et ArgoCD soutient nos efforts d'automatisation et d'efficacit\u00e9, en assurant que les secrets soient g\u00e9r\u00e9s et d\u00e9ploy\u00e9s de mani\u00e8re s\u00e9curis\u00e9e dans notre environnement. Cette d\u00e9cision n\u00e9cessitera une formation de nos \u00e9quipes sur Vault et l'ajustement de nos processus existants pour int\u00e9grer pleinement Vault dans notre pipeline CI/CD.</p>"},{"location":"adr/012-secret-management.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Documentation sur notre configuration et utilisation de HashiCorp   Vault</li> <li>Documentation officielle de HashiCorp   Vault</li> <li>Int\u00e9gration de HashiCorp Vault avec   Kubernetes</li> <li>Guide sur l'int\u00e9gration de HashiCorp Vault avec   ArgoCD</li> <li>Vault-action pour int\u00e9grer Vault dans nos pipelines   CI/CD</li> <li>Aper\u00e7u Azure Key   Vault</li> <li>Repertoire Mozilla SOPS</li> <li>Azure key vault action   obsol\u00e8te</li> </ul>"},{"location":"adr/013-IaC-tool.fr-ca/","title":"ADR-013 : Gestion de l'Infrastructure as Code (IaC)","text":""},{"location":"adr/013-IaC-tool.fr-ca/#resume-executif","title":"R\u00e9sum\u00e9 Ex\u00e9cutif","text":"<p>Nous avons d\u00e9cid\u00e9 d'adopter Terraform comme solution d'Infrastructure as Code (IaC) pour la gestion et le d\u00e9ploiement de notre infrastructure sur plusieurs fournisseurs de cloud. Cette d\u00e9cision s'appuie sur la compatibilit\u00e9 interinfonuagique de Terraform, notre connaissance approfondie de l'outil, ainsi que ses capacit\u00e9s de suivi d'\u00e9tat. Terraform offre \u00e9galement une maturit\u00e9 et une communaut\u00e9 plus larges, sans \u00eatre li\u00e9 \u00e0 un fournisseur de nuage sp\u00e9cifique, et permet la cr\u00e9ation de fournisseurs d'extensibilit\u00e9 personnalis\u00e9s.</p>"},{"location":"adr/013-IaC-tool.fr-ca/#contexte","title":"Contexte","text":"<p>Dans le cadre de notre effort pour am\u00e9liorer l'efficacit\u00e9 et la reproductibilit\u00e9 de la gestion de notre infrastructure infonuagique, nous avons \u00e9valu\u00e9 plusieurs outils d'Infrastructure as Code (IaC). Notre infrastructure, bien que principalement h\u00e9berg\u00e9e sur Azure pour le moment, pourrait s'\u00e9tendre \u00e0 d'autres fournisseurs \u00e0 l'avenir, soulignant l'importance d'un outil IaC flexible et puissant.</p> <p>L'utilisation d'un outil IaC nous permet de b\u00e9n\u00e9ficier du contr\u00f4le de version de notre infrastructure, similaire \u00e0 ce que Git offre pour le code source. Cela signifie que nous pouvons suivre, r\u00e9viser et reverser les changements d'infrastructure de mani\u00e8re contr\u00f4l\u00e9e et document\u00e9e. De plus, un outil IaC r\u00e9duit consid\u00e9rablement le temps requis pour la provision et la gestion de l'infrastructure, car il permet de d\u00e9ployer et d'actualiser l'infrastructure \u00e0 travers des fichiers de configuration au lieu de proc\u00e9dures manuelles. Cette approche garantit \u00e9galement un environnement plus coh\u00e9rent, en r\u00e9duisant les divergences entre les environnements de d\u00e9veloppement, de test, et de production. Enfin, en automatisant la gestion de l'infrastructure, nous minimisons le risque d'erreurs humaines, am\u00e9liorant ainsi la s\u00e9curit\u00e9 et la fiabilit\u00e9 de nos syst\u00e8mes.</p>"},{"location":"adr/013-IaC-tool.fr-ca/#decision","title":"D\u00e9cision","text":"<p>Apr\u00e8s une \u00e9valuation approfondie, nous avons choisi Terraform comme notre outil de gestion d'infrastructure. Cette d\u00e9cision repose sur plusieurs facteurs cl\u00e9s : Notre exp\u00e9rience existante avec cet outil, la compatibilit\u00e9 inter-cloud de Terraform gr\u00e2ce \u00e0 un mod\u00e8le de travail coh\u00e9rent \u00e0 travers un langage descriptif et sa fonctionnalit\u00e9 de fichier d'\u00e9tat qui facilite le suivi des changements d'infrastructure. De plus, la maturit\u00e9 de Terraform et sa vaste communaut\u00e9 offrent une assurance suppl\u00e9mentaire quant \u00e0 la fiabilit\u00e9 et l'\u00e9volutivit\u00e9 de cet outil. Terraform nous permet \u00e9galement de cr\u00e9er des fournisseurs d'extensibilit\u00e9 personnalis\u00e9s, une fonctionnalit\u00e9 essentielle pour notre projet qui n\u00e9cessitent l'int\u00e9gration avec HashiCorp Vault et GitHub. Ainsi, Terraform nous permet d'utiliser des fournisseurs tels que Helm, Kubernetes, ArgoCD, Azure DevOps, GitHub, Ansible, et bien d'autres encore.</p>"},{"location":"adr/013-IaC-tool.fr-ca/#alternatives-considerees","title":"Alternatives Consid\u00e9r\u00e9es","text":""},{"location":"adr/013-IaC-tool.fr-ca/#bicep","title":"Bicep","text":"<p>Avantages :</p> <ul> <li>Int\u00e9gration native avec Azure, offrant une exp\u00e9rience simplifi\u00e9e pour la   gestion des ressources Azure.</li> <li>Syntaxe simplifi\u00e9e par rapport \u00e0 des outils plus anciens comme Azure Resource   Manager (ARM) templates.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Absence de gestion d'\u00e9tat int\u00e9gr\u00e9e : contrairement \u00e0 Terraform qui dispose   d'une fonctionnalit\u00e9 de fichier d'\u00e9tat permettant de suivre et de g\u00e9rer les   changements dans l'infrastructure (si un \u00e9l\u00e9ment est supprim\u00e9 du code de   d\u00e9ploiement, Terraform proc\u00e8de \u00e0 sa destruction), Bicep ne poss\u00e8de pas de   concept similaire. Cela signifie que les modifications ou suppressions   d'\u00e9l\u00e9ments n\u00e9cessitent une intervention manuelle ou une logique suppl\u00e9mentaire   pour g\u00e9rer l'\u00e9tat de l'infrastructure.</li> <li>Limit\u00e9 principalement \u00e0 l'\u00e9cosyst\u00e8me Azure, ce qui pose des d\u00e9fis pour les d\u00e9ploiements multi-infonuagiques.</li> <li>La cr\u00e9ation de fournisseurs d'extensibilit\u00e9 personnalis\u00e9s est encore en phase   exp\u00e9rimentale.</li> </ul>"},{"location":"adr/013-IaC-tool.fr-ca/#cloudformation","title":"CloudFormation","text":"<p>Avantages :</p> <ul> <li>Int\u00e9gration profonde avec l'\u00e9cosyst\u00e8me AWS, facilitant la gestion des   ressources AWS.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Confin\u00e9 \u00e0 l'\u00e9cosyst\u00e8me AWS, limitant la flexibilit\u00e9 pour les d\u00e9ploiements   multi-cloud.</li> <li>Moins de support pour l'extensibilit\u00e9 personnalis\u00e9e par rapport \u00e0 Terraform.</li> </ul>"},{"location":"adr/013-IaC-tool.fr-ca/#pulumi","title":"Pulumi","text":"<p>Avantages :</p> <ul> <li>Langages de Programmation Familiers : Pulumi permet aux d\u00e9veloppeurs   d'utiliser des langages de programmation g\u00e9n\u00e9raux tels que TypeScript, Python,   Go, et .NET, ce qui peut r\u00e9duire la courbe d'apprentissage et faciliter   l'int\u00e9gration dans les pipelines CI/CD existants.</li> <li>\u00c9tat G\u00e9r\u00e9 en Cloud : Pulumi g\u00e8re l'\u00e9tat de l'infrastructure dans le cloud,   offrant une approche centralis\u00e9e et s\u00e9curis\u00e9e pour le suivi des d\u00e9ploiements   d'infrastructure.</li> <li>Support Multi-Cloud et On-Premise : Pulumi fournit une large prise en charge   des fournisseurs de cloud, y compris Azure, AWS, Google Cloud, ainsi que des   ressources on-premise, offrant une grande flexibilit\u00e9 pour les d\u00e9ploiements   hybrides et multi-cloud.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Complexit\u00e9 potentielle : L'utilisation de langages de programmation complets   peut introduire une complexit\u00e9 suppl\u00e9mentaire dans la gestion de   l'infrastructure, surtout pour les \u00e9quipes non famili\u00e8res avec ces langages.</li> <li>D\u00e9pendance sur le Service Pulumi : Bien que Pulumi offre des options pour   g\u00e9rer l'\u00e9tat localement ou dans le nuage, la version g\u00e9r\u00e9e en nuage cr\u00e9e une   d\u00e9pendance sur les services de Pulumi, ce qui apporte des pr\u00e9occupations  vis-\u00e0-vis la souverainet\u00e9 des donn\u00e9es ou les co\u00fbts suppl\u00e9mentaires.</li> <li>Moins Mature que Terraform : Pulumi est plus r\u00e9cent sur le march\u00e9 de l'IaC que   Terraform, ce qui signifie qu'il pourrait avoir une communaut\u00e9 plus petite et   moins de ressources disponibles pour le d\u00e9pannage et l'apprentissage compar\u00e9 \u00e0   Terraform.</li> </ul>"},{"location":"adr/013-IaC-tool.fr-ca/#consequences","title":"Cons\u00e9quences","text":"<p>L'adoption de Terraform comme notre outil IaC principal nous permettront d'unifier la gestion de notre infrastructure \u00e0 travers divers fournisseurs, am\u00e9liorant ainsi l'efficacit\u00e9 et r\u00e9duisant le risque d'erreurs manuelles. Cela n\u00e9cessitera une formation continue pour nos \u00e9quipes afin d'exploiter pleinement les capacit\u00e9s de Terraform. Nous anticipons \u00e9galement une am\u00e9lioration de la collaboration entre les \u00e9quipes de d\u00e9veloppement, d'op\u00e9rations et de s\u00e9curit\u00e9 gr\u00e2ce \u00e0 une approche coh\u00e9rente de la gestion des infrastructures. La d\u00e9cision soutient notre objectif d'agilit\u00e9 et de s\u00e9curit\u00e9 dans le d\u00e9veloppement et le d\u00e9ploiement de nos applications, tout en promouvant l'utilisation de solutions qui nous permet d'\u00eatre open source pour une plus grande transparence et collaboration.</p>"},{"location":"adr/013-IaC-tool.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Documentation sur le flux de travail avec Terraform pour faire le d\u00e9ploiement   de nos services</li> <li>Code source de l'infrastructure   (Howard)</li> <li>Site officiel de Terraform</li> <li>Documentation de   Bicep</li> <li>Repertoire Github de Pulumi</li> <li>Guide de l'utilisateur AWS   CloudFormation</li> <li>Extensibilit\u00e9 de fournisseurs en phase exp\u00e9rimentale pour Biceps</li> </ul>"},{"location":"adr/014-containers.fr-ca/","title":"ADR-014 : Conteneurisation","text":""},{"location":"adr/014-containers.fr-ca/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>L'utilisation de conteneurs et de Kubernetes s'est av\u00e9r\u00e9e efficace pour la gestion et le d\u00e9ploiement de nos applications. Cette approche offre plusieurs avantages, notamment la portabilit\u00e9, qui permet aux conteneurs de s'ex\u00e9cuter de mani\u00e8re coh\u00e9rente sur diff\u00e9rents environnements, simplifiant ainsi le d\u00e9veloppement et le d\u00e9ploiement. L'\u00e9volutivit\u00e9 est \u00e9galement un point fort, car Kubernetes permet de faire \u00e9voluer facilement les applications en fonction de la demande. En termes de fiabilit\u00e9, les conteneurs et Kubernetes offrent une meilleure r\u00e9sistance aux pannes et une haute disponibilit\u00e9. Enfin, l'efficacit\u00e9 est am\u00e9lior\u00e9e gr\u00e2ce \u00e0 l'utilisation de conteneurs qui optimisent l'utilisation des ressources et r\u00e9duit les co\u00fbts.</p>"},{"location":"adr/014-containers.fr-ca/#contexte","title":"Contexte","text":"<p>Auparavant, nous d\u00e9ployions manuellement chaque Dockerfile sur Google Cloud Run. Cette approche nous demandait un investissement de temps consid\u00e9rable, car chaque d\u00e9ploiement n\u00e9cessitait une intervention manuelle pour la construction et la mise en ligne des conteneurs. Malgr\u00e9 la pr\u00e9sence syst\u00e9matique de Dockerfiles dans nos r\u00e9pertoires, le processus de d\u00e9veloppement et de d\u00e9ploiement restait relativement peu automatis\u00e9.</p>"},{"location":"adr/014-containers.fr-ca/#decision","title":"D\u00e9cision","text":"<p>Pour pallier ces limitations, nous avons d\u00e9cid\u00e9 d'adopter Kubernetes pour l'orchestration des conteneurs. Cette transition nous permet de b\u00e9n\u00e9ficier d'une gestion plus robuste et \u00e9volutive de nos applications. Cependant, le d\u00e9ploiement n'est pas enti\u00e8rement automatis\u00e9 ; les manifestes Kubernetes doivent \u00eatre cr\u00e9\u00e9s pour ensuite \u00eatre d\u00e9ploy\u00e9s via ArgoCD, offrant ainsi un niveau suppl\u00e9mentaire de contr\u00f4le et de validation avant le d\u00e9ploiement final.</p> <p>En ce qui concerne les images Docker, nous avons mis en place un flux de travail GitHub qui automatise le processus de construction, de \"tagging\" et de mise en ligne. Cette automatisation nous permet de garantir la coh\u00e9rence et la fiabilit\u00e9 de nos d\u00e9ploiements tout en r\u00e9duisant la charge de travail manuelle et les risques d'erreurs.</p>"},{"location":"adr/014-containers.fr-ca/#alternatives-considerees","title":"Alternatives Consid\u00e9r\u00e9es","text":""},{"location":"adr/014-containers.fr-ca/#docker-swarm","title":"Docker Swarm","text":"<p>Avantages:</p> <ul> <li> <p>Int\u00e9gration native avec Docker: Docker Swarm est \u00e9troitement int\u00e9gr\u00e9 \u00e0 Docker et utilise le Docker API, ce qui rend la mise en place et la gestion plus simple pour les \u00e9quipes d\u00e9j\u00e0 habitu\u00e9es \u00e0 Docker.</p> </li> <li> <p>Facilit\u00e9 de d\u00e9ploiement: Docker Swarm est plus simple \u00e0 configurer et \u00e0 g\u00e9rer par rapport \u00e0 Kubernetes, ce qui peut \u00eatre b\u00e9n\u00e9fique pour les petites ou moyennes infrastructures sans besoins complexes.</p> </li> <li> <p>Performances: Docker Swarm a souvent montr\u00e9 des performances meilleures en termes de temps de d\u00e9marrage des conteneurs et d\u2019utilisation des ressources.</p> </li> </ul> <p>Inconv\u00e9nients:</p> <ul> <li> <p>Scalabilit\u00e9 limit\u00e9e: Docker Swarm est moins adapt\u00e9 pour les grands clusters que Kubernetes. Kubernetes excelle dans la gestion de clusters de grande taille et complexes.</p> </li> <li> <p>Fonctionnalit\u00e9s moins robustes: Par rapport \u00e0 Kubernetes, Docker Swarm offre moins de fonctionnalit\u00e9s avanc\u00e9es comme les strat\u00e9gies de d\u00e9ploiement sophistiqu\u00e9es, la gestion avanc\u00e9e des volumes, et le support extensif pour les outils de CI/CD.</p> </li> <li> <p>Communaut\u00e9 plus petite: La communaut\u00e9 autour de Docker Swarm est moins active que celle de Kubernetes, ce qui peut impacter le support et le d\u00e9veloppement de nouvelles fonctionnalit\u00e9s.</p> </li> </ul>"},{"location":"adr/014-containers.fr-ca/#nomad","title":"Nomad","text":"<p>Avantages:</p> <ul> <li> <p>Simplicit\u00e9 et flexibilit\u00e9: Nomad est r\u00e9put\u00e9 pour sa simplicit\u00e9 et sa flexibilit\u00e9. Cela rend l'orchestrateur id\u00e9al pour les applications non conteneuris\u00e9es ainsi que pour les conteneurs.</p> </li> <li> <p>Ressources h\u00e9t\u00e9rog\u00e8nes et multi-r\u00e9gion: Nomad peut g\u00e9rer des charges de travail sur diff\u00e9rents types de serveurs, y compris des environnements bare metal, VMs ou conteneuris\u00e9s, et peut g\u00e9rer des clusters multi-r\u00e9gion facilement.</p> </li> <li> <p>Haute performance et efficacit\u00e9: Nomad est con\u00e7u pour \u00eatre performant \u00e0 grande \u00e9chelle, offrant un d\u00e9marrage rapide des t\u00e2ches et une surcharge minimale.</p> </li> </ul> <p>Inconv\u00e9nients:</p> <ul> <li> <p>Moins de fonctionnalit\u00e9s que certains concurrents: Bien que Nomad soit appr\u00e9ci\u00e9 pour sa simplicit\u00e9, il peut manquer de certaines fonctionnalit\u00e9s avanc\u00e9es pr\u00e9sentes dans d'autres orchestrateurs, comme Kubernetes.</p> </li> <li> <p>\u00c9cosyst\u00e8me plus restreint: L'\u00e9cosyst\u00e8me autour de Nomad est moins d\u00e9velopp\u00e9 comparativement \u00e0 celui de solutions plus m\u00fbres comme Kubernetes. Ceci peut se traduire par une offre plus limit\u00e9e en termes d'outils tiers, de plugins ou d'int\u00e9grations, rendant certaines t\u00e2ches plus complexes \u00e0 mettre en \u0153uvre et \u00e0 maintenir.</p> </li> </ul>"},{"location":"adr/014-containers.fr-ca/#conclusion","title":"Conclusion","text":"<p>L'adoption de Kubernetes s'est av\u00e9r\u00e9e \u00eatre une d\u00e9cision judicieuse pour la gestion et le d\u00e9ploiement de nos applications conteneuris\u00e9es. Cette approche a permis d'am\u00e9liorer la portabilit\u00e9, l'\u00e9volutivit\u00e9, la fiabilit\u00e9 ainsi que l'efficacit\u00e9 de nos applications.</p>"},{"location":"adr/014-containers.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<p>Kubernetes</p> <p>Docker</p> <p>Docker swarm</p> <p>Nomad</p>"},{"location":"adr/015-authentication-management.fr-ca/","title":"ADR-015 : Gestion d'authentification des utilisateurs","text":""},{"location":"adr/015-authentication-management.fr-ca/#resume-executif","title":"R\u00e9sum\u00e9 Ex\u00e9cutif","text":"<p>Dans le cadre de la gestion centralis\u00e9e de l'authentification des utilisateurs pour nos applications, notamment l'application Nachet, nous avons choisi d'impl\u00e9menter Vouch-proxy. Cette solution a \u00e9t\u00e9 s\u00e9lectionn\u00e9e pour sa capacit\u00e9 \u00e0 int\u00e9grer de mani\u00e8re efficace les services d'authentification tels qu'Azure et Github, tout en r\u00e9cup\u00e9rant les informations de groupe des utilisateurs dans un token. Vouch-proxy nous permet d'appliquer une gestion d'authentification uniforme et s\u00e9curis\u00e9e pour tous les services h\u00e9berg\u00e9s sur notre cluster Kubernetes, gr\u00e2ce \u00e0 son int\u00e9gration avec l'ingress NGINX. Ce choix vise \u00e0 am\u00e9liorer la s\u00e9curit\u00e9 tout en offrant une flexibilit\u00e9 et une \u00e9volutivit\u00e9 accrues pour nos op\u00e9rations de gestion d'identit\u00e9 et d'acc\u00e8s.</p>"},{"location":"adr/015-authentication-management.fr-ca/#contexte","title":"Contexte","text":"<p>Certaines de nos applications, dont l'application Nachet, requi\u00e8rent une authentification pour acc\u00e9der \u00e0 leurs services. Initialement, Nachet a \u00e9t\u00e9 d\u00e9ploy\u00e9e sans m\u00e9canismes d'authentification, permettant ainsi \u00e0 n'importe quel utilisateur de consulter la page et potentiellement d'y ins\u00e9rer des images malveillantes. Face \u00e0 cette vuln\u00e9rabilit\u00e9, et afin de s\u00e9curiser l'acc\u00e8s \u00e0 l'ensemble des applications sur notre cluster Kubernetes, il est devenu imp\u00e9ratif d'adopter une solution d'authentification centralis\u00e9e. Cette solution doit \u00e9galement \u00eatre capable de s'int\u00e9grer avec les fournisseurs d'identit\u00e9 tels que Azure et Github, et de r\u00e9cup\u00e9rer les groupes d'utilisateurs dans un token pour une gestion fine des autorisations.</p>"},{"location":"adr/015-authentication-management.fr-ca/#decision","title":"D\u00e9cision","text":"<p>Apr\u00e8s avoir \u00e9valu\u00e9 plusieurs alternatives, nous avons opt\u00e9 pour l'utilisation de Vouch-proxy pour r\u00e9pondre \u00e0 nos besoins d'authentification centralis\u00e9e. Vouch-proxy se distingue par sa compatibilit\u00e9 avec les fournisseurs d'identit\u00e9 Azure et Github, facilitant ainsi l'authentification des utilisateurs tout en r\u00e9cup\u00e9rant les informations essentielles des groupes dans un token. Cette capacit\u00e9 nous est cruciale pour la gestion des autorisations au sein de nos services. En outre, Vouch-proxy s'int\u00e8gre parfaitement \u00e0 l'ingress NGINX de notre cluster Kubernetes, permettant une gestion centralis\u00e9e de l'authentification pour tous nos services. Cette approche centralis\u00e9e garantit une s\u00e9curit\u00e9 renforc\u00e9e et une meilleure coh\u00e9rence dans la gestion des acc\u00e8s utilisateurs \u00e0 travers diff\u00e9rentes applications.</p>"},{"location":"adr/015-authentication-management.fr-ca/#alternatives-considerees","title":"Alternatives Consid\u00e9r\u00e9es","text":""},{"location":"adr/015-authentication-management.fr-ca/#ori-network-ori-oathkeeper-ori-kratos","title":"Ori network (Ori Oathkeeper, Ori Kratos)","text":"<p>Avantages :</p> <ul> <li>Ori Oathkeeper est un proxy d'authentification et d'autorisation qui peut \u00eatre   utilis\u00e9 pour g\u00e9rer l'authentification des utilisateurs et des services de   facons centralis\u00e9e. Ori Kratos est un service d'identit\u00e9 et d'acc\u00e8s qui peut   \u00eatre utilis\u00e9 pour g\u00e9rer les utilisateurs et les r\u00f4les de mani\u00e8re centralis\u00e9e.   L'avantage de ces solutions est qu'elles peuvent \u00eatre utilis\u00e9es comme solution   compl\u00e8te pour g\u00e9rer l'authentification et l'autorisation des utilisateurs et   des services.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Ori Oathkeeper et Ori Kratos sont des solutions relativement nouvelles et se   sont av\u00e9r\u00e9es moins matures que d'autres solutions d'authentification. Nous   avons essayer un d\u00e9ploiement de Kratos et avons rencontr\u00e9 des probl\u00e8mes de   configuration entre autres. La documentation est \u00e9galement moins compl\u00e8te que   celle d'autres solutions.</li> </ul>"},{"location":"adr/015-authentication-management.fr-ca/#oauth2-proxy","title":"Oauth2-Proxy","text":"<p>Avantages :</p> <ul> <li>Oauth2-Proxy est un proxy d'authentification qui peut \u00eatre utilis\u00e9 pour g\u00e9rer   l'authentification des utilisateurs et peut \u00eatre configur\u00e9 avec le ingress   NGINX.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Oauth2-Proxy est configurable pour g\u00e9rer l'authentification 1 pour 1, mais   n'est pas con\u00e7u pour g\u00e9rer l'authentification de mani\u00e8re centralis\u00e9e pour   plusieurs services. Vouch-proxy est une alternative plus adapt\u00e9e \u00e0 nos besoins   de gestion d'authentification centralis\u00e9e.</li> </ul>"},{"location":"adr/015-authentication-management.fr-ca/#solution-sur-mesure-pour-lauthentification","title":"Solution sur mesure pour l'authentification","text":"<p>Avantages :</p> <ul> <li>Adaptation pr\u00e9cise : Une solution sur mesure offre la possibilit\u00e9 de   d\u00e9velopper un syst\u00e8me d'authentification qui correspond pr\u00e9cis\u00e9ment aux   exigences sp\u00e9cifiques de notre infrastructure et de nos applications. Cela   permet une int\u00e9gration plus fine et adapt\u00e9e aux processus internes.</li> <li>Contr\u00f4le complet : En concevant notre propre solution, nous b\u00e9n\u00e9ficions d'un   contr\u00f4le total sur les aspects de s\u00e9curit\u00e9 et de fonctionnalit\u00e9, nous   permettant ainsi d'ajuster ou d'am\u00e9liorer la solution en fonction des   \u00e9volutions des besoins de s\u00e9curit\u00e9 et de gestion des utilisateurs.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Co\u00fbt et temps de d\u00e9veloppement \u00e9lev\u00e9s : La conception d'une solution   personnalis\u00e9e exige un investissement initial significatif en temps et en   ressources humaines.</li> <li>Maintenance et mise \u00e0 jour : Les co\u00fbts op\u00e9rationnels post-d\u00e9veloppement   peuvent \u00eatre importants, incluant la maintenance r\u00e9guli\u00e8re et les mises \u00e0 jour   n\u00e9cessaires pour r\u00e9pondre aux nouvelles menaces de s\u00e9curit\u00e9 et aux exigences   l\u00e9gales.</li> <li>Comp\u00e9titivit\u00e9 et maturit\u00e9 : Il est difficile pour une solution interne de   rivaliser avec les fonctionnalit\u00e9s et la s\u00e9curit\u00e9 offertes par des solutions   \u00e9prouv\u00e9es sur le march\u00e9, qui b\u00e9n\u00e9ficient d'un d\u00e9veloppement continu et du   retour d'exp\u00e9rience d'une large base d'utilisateurs.</li> </ul>"},{"location":"adr/015-authentication-management.fr-ca/#consequences","title":"Cons\u00e9quences","text":"<p>L'adoption de Vouch-proxy pour l'authentification centralis\u00e9e au sein de notre infrastructure pr\u00e9sente des implications significatives, tant positives que n\u00e9gatives. Sur le plan positif, cette d\u00e9cision renforcera la s\u00e9curit\u00e9 de nos applications en int\u00e9grant efficacement des services d'authentification robustes tels qu'Azure et Github, tout en facilitant la gestion des droits d'acc\u00e8s gr\u00e2ce \u00e0 la r\u00e9cup\u00e9ration des groupes d'utilisateurs dans un token. Cela simplifiera \u00e9galement l'administration de nos syst\u00e8mes et am\u00e9liorera la coh\u00e9rence de l'exp\u00e9rience utilisateur \u00e0 travers diff\u00e9rentes applications. Toutefois, il est essentiel de reconna\u00eetre que cette mise en \u0153uvre n\u00e9cessitera des ajustements techniques, notamment dans la configuration et le maintien de l'ingress NGINX, et pourrait introduire une complexit\u00e9 initiale lors de la phase d'int\u00e9gration. De plus, cette d\u00e9cision engage l'entreprise \u00e0 d\u00e9pendre de la p\u00e9rennit\u00e9 et de l'\u00e9volution de Vouch-proxy, ainsi que de la stabilit\u00e9 de ses int\u00e9grations avec les fournisseurs d'identit\u00e9. Il sera donc crucial de suivre de pr\u00e8s ces aspects et de pr\u00e9voir des plans d'action pour les mises \u00e0 jour n\u00e9cessaires et les \u00e9ventuels ajustements en r\u00e9ponse aux d\u00e9fis qui pourraient survenir.</p>"},{"location":"adr/015-authentication-management.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Oauth2-Proxy</li> <li>Vouch-proxy</li> <li>Ori Oathkeeper</li> <li>Ori Kratos</li> <li>Example of implementing authentication with Express Web   app</li> </ul>"},{"location":"adr/016-networking.fr-ca/","title":"ADR-016 : R\u00e9seautique","text":""},{"location":"adr/016-networking.fr-ca/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>Cette d\u00e9cision d'architecture vise \u00e0 formaliser la strat\u00e9gie de r\u00e9seautique pour nos applications d\u00e9ploy\u00e9es sur Kubernetes, en \u00e9valuant les composants actuels et futures d'acc\u00e8s r\u00e9seau pour maximiser performance, s\u00e9curit\u00e9 et facilit\u00e9 de gestion. Nous utilisons Azure pour cette architecture, en int\u00e9grant ingress Nginx, cert-manager, vouch-proxy, ainsi qu'une gestion automatique des enregistrements DNS gr\u00e2ce \u00e0 external-dns.</p>"},{"location":"adr/016-networking.fr-ca/#contexte","title":"Contexte","text":"<p>Dans notre architecture Kubernetes actuelle, nous utilisons ingress Nginx pour le contr\u00f4le d'acc\u00e8s, g\u00e9r\u00e9 par une IP statique attribu\u00e9e par Azure. Nous automatisons la cr\u00e9ation des enregistrements CNAME pour nos services via external-dns, ce qui facilite significativement la gestion des DNS. En outre, cert-manager est d\u00e9ploy\u00e9 pour la gestion automatique des certificats SSL, s\u00e9curisant ainsi les communications, tandis que vouch-proxy g\u00e8re l'acc\u00e8s s\u00e9curis\u00e9 aux applications. Notre domaine <code>.inspection.alpha.canada.ca</code> est g\u00e9r\u00e9 dans une zone DNS sur Azure, b\u00e9n\u00e9ficiant d'une int\u00e9gration directe avec ces services.</p>"},{"location":"adr/016-networking.fr-ca/#decision","title":"D\u00e9cision","text":"<p>Nous recommandons de maintenir l'utilisation de Nginx Ingress, cert-manager, et vouch-proxy, en combinant ces services avec la gestion DNS automatis\u00e9e par external-dns. Cette configuration nous offre robustesse, souplesse et s\u00e9curit\u00e9, en harmonie avec les services d'Azure.</p>"},{"location":"adr/016-networking.fr-ca/#alternatives-considerees","title":"Alternatives Consid\u00e9r\u00e9es","text":""},{"location":"adr/016-networking.fr-ca/#istio-ingress","title":"Istio Ingress","text":"<p>Avantages:</p> <ul> <li> <p>Int\u00e9gration des services mesh: Offre une gestion avanc\u00e9e du routage, de l\u2019\u00e9quilibrage de charge, et des politiques de s\u00e9curit\u00e9 \u00e0 l'\u00e9chelle des services.</p> </li> <li> <p>Granularit\u00e9 des politiques r\u00e9seau: Permet une gestion d\u00e9taill\u00e9e des politiques r\u00e9seau entre services.</p> </li> </ul> <p>Inconv\u00e9nients:</p> <ul> <li> <p>Complexit\u00e9: Sa configuration et sa gestion sont complexes et peuvent repr\u00e9senter un d\u00e9fi en termes de maintenance.</p> </li> <li> <p>Consommation de ressources: Istio est plus gourmand en ressources, ce qui peut \u00eatre probl\u00e9matique dans des environnements \u00e0 capacit\u00e9 limit\u00e9e.</p> </li> </ul>"},{"location":"adr/016-networking.fr-ca/#kubernetes-gateway-api","title":"Kubernetes Gateway API","text":"<p>Avantages:</p> <ul> <li> <p>Standard en \u00e9volution: Propose un mod\u00e8le plus expressif que les Ingress traditionnels avec une meilleure abstraction pour les routes.</p> </li> <li> <p>Modularit\u00e9 et flexibilit\u00e9: Offre une forte personnalisation dans la gestion du trafic et des routes.</p> </li> </ul> <p>Inconv\u00e9nients:</p> <ul> <li> <p>Maturit\u00e9 et adoption: \u00c9tant donn\u00e9 sa nouveaut\u00e9, l'adoption du Gateway API n\u2019est pas encore g\u00e9n\u00e9ralis\u00e9e et pourrait manquer de support compar\u00e9 \u00e0 des solutions \u00e9tablies.</p> </li> <li> <p>Redondance possible: Certaines capacit\u00e9s peuvent chevaucher celles fournies par Nginx Ingress, n\u00e9cessitant potentiellement une r\u00e9\u00e9valuation des outils en place.</p> </li> </ul>"},{"location":"adr/016-networking.fr-ca/#conclusion","title":"Conclusion","text":"<p>La configuration actuelle utilisant Nginx Ingress, cert-manager, vouch-proxy, et external-dns pour la gestion automatique des enregistrements DNS fournit un \u00e9quilibre optimal entre efficacit\u00e9, s\u00e9curit\u00e9 et gestion simplifi\u00e9e dans notre environnement Azure. Ces choix appuient notre strat\u00e9gie de maintenir une architecture stable tout en exploitant au maximum les comp\u00e9tences et les technologies que nous ma\u00eetrisons d\u00e9j\u00e0. Continuer sur cette voie nous permet de b\u00e9n\u00e9ficier d'une int\u00e9gration et d'un support solides par Azure, tout en facilitant la scalabilit\u00e9 et la maintenance de nos services de r\u00e9seautique.</p>"},{"location":"adr/016-networking.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Implementation dans Howard</li> <li>Implementation de Vouch proxy dans Howard</li> <li>Istio ingress</li> <li>Kubernetes gateway api</li> <li>Ingress NGINX</li> <li>Cert manager</li> <li>External DNS</li> </ul>"},{"location":"adr/017-security.fr-ca/","title":"ADR-017 : S\u00e9curit\u00e9","text":""},{"location":"adr/017-security.fr-ca/#resume-executif","title":"R\u00e9sum\u00e9 ex\u00e9cutif","text":"<p>Cet ADR documente et formalise l'am\u00e9lioration de notre strat\u00e9gie de s\u00e9curit\u00e9 \u00e0 travers la gestion et la surveillance des vuln\u00e9rabilit\u00e9s au sein de notre infrastructure Kubernetes. Nous avons enrichi nos capacit\u00e9s de s\u00e9curit\u00e9 en int\u00e9grant trivy-operator et Falco pour les scans statiques et dynamiques, tout en continuant d'utiliser Dependabot pour les d\u00e9pendances de code. Par ailleurs, nous avons adopt\u00e9 Mend Renovate pour automatiser les mises \u00e0 jour des images Docker, des providers Terraform, et autres d\u00e9pendances \u00e0 des fins de maintien des versions les plus s\u00e9curis\u00e9es. Le suivi et la visualisation de ces mesures de s\u00e9curit\u00e9 sont r\u00e9alis\u00e9s \u00e0 travers des dashboards Grafana.</p>"},{"location":"adr/017-security.fr-ca/#contexte","title":"Contexte","text":"<p>Traditionnellement, notre strat\u00e9gie de s\u00e9curit\u00e9 s'appuyait principalement sur Dependabot pour les alertes de s\u00e9curit\u00e9 concernant les d\u00e9pendances de notre code. Face \u00e0 des exigences de s\u00e9curit\u00e9 accrues et \u00e0 la n\u00e9cessit\u00e9 de couvrir les vuln\u00e9rabilit\u00e9s tant au niveau statique que dynamique, nous avons \u00e9largi notre suite d'outils de s\u00e9curit\u00e9.</p>"},{"location":"adr/017-security.fr-ca/#decision","title":"D\u00e9cision","text":"<p>Nous avons renforc\u00e9 notre architecture de s\u00e9curit\u00e9 en int\u00e9grant les outils suivants :</p> <ul> <li> <p>Trivy-operator : r\u00e9alise des scans statiques de notre cluster et des images des conteneurs de nos pods pour d\u00e9tecter les vuln\u00e9rabilit\u00e9s avant leur d\u00e9ploiement.</p> </li> <li> <p>Falco : effectue des scans dynamiques pour surveiller le comportement en temps r\u00e9el des applications et d\u00e9tecter toute activit\u00e9 anormale ou suspecte.</p> </li> <li> <p>Mend Renovate : automatise la mise \u00e0 jour des versions de nos images Docker, des providers Terraform, et d'autres d\u00e9pendances, assurant l'usage des versions les plus r\u00e9centes et s\u00e9curis\u00e9es.</p> </li> </ul> <p>Ces outils sont compl\u00e9ment\u00e9s par des dashboards Grafana, permettant une visualisation en temps r\u00e9el et une gestion des alertes de s\u00e9curit\u00e9, facilitant une intervention rapide et \u00e9clair\u00e9e.</p>"},{"location":"adr/017-security.fr-ca/#alternatives-considerees","title":"Alternatives Consid\u00e9r\u00e9es","text":""},{"location":"adr/017-security.fr-ca/#snyk","title":"Snyk","text":"<p>Avantages :</p> <ul> <li> <p>S\u00e9curit\u00e9 proactive : Snyk offre une solution proactive en testant les d\u00e9pendances et les conteneurs en qu\u00eate de vuln\u00e9rabilit\u00e9s et en proposant des corrections automatis\u00e9es.</p> </li> <li> <p>Large \u00e9ventail d'int\u00e9grations : S\u2019int\u00e8gre facilement avec des outils de CI/CD et des plateformes d'h\u00e9bergement, comme GitHub et Bitbucket, pour une d\u00e9tection et une correction automatis\u00e9e des vuln\u00e9rabilit\u00e9s au sein du pipeline de d\u00e9veloppement.</p> </li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li> <p>Co\u00fbt potentiellement \u00e9lev\u00e9 : Les fonctionnalit\u00e9s avanc\u00e9es de Snyk peuvent repr\u00e9senter un co\u00fbt significatif, surtout pour les grandes organisations avec de nombreux environnements \u00e0 g\u00e9rer.</p> </li> <li> <p>Apprentissage et configuration : La mise en place et l'optimisation de Snyk pour des environnements sp\u00e9cifiques peuvent requ\u00e9rir un certain temps d'adaptation et de configuration.</p> </li> </ul>"},{"location":"adr/017-security.fr-ca/#sysdig-secure","title":"Sysdig Secure","text":"<p>Avantages :</p> <ul> <li> <p>Inspection d\u00e9taill\u00e9e : Permet une analyse approfondie du trafic r\u00e9seau et du syst\u00e8me de fichiers en temps r\u00e9el.</p> </li> <li> <p>Compatibilit\u00e9 \u00e9tendue : Compatible avec la plupart des environnements de cloud et d'orchestrateurs de conteneurs.</p> </li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li> <p>Utilisation intensive des ressources : Peut consommer une quantit\u00e9 significative de ressources syst\u00e8me, impactant les performances.</p> </li> <li> <p>Complexit\u00e9 d'int\u00e9gration : Bien que puissant, il peut s'av\u00e9rer difficile \u00e0 int\u00e9grer et n\u00e9cessite une maintenance r\u00e9guli\u00e8re pour rester synchronis\u00e9 avec les mises \u00e0 jour des syst\u00e8mes et des orchestrateurs.</p> </li> </ul>"},{"location":"adr/017-security.fr-ca/#conclusion","title":"Conclusion","text":"<p>L'int\u00e9gration de trivy-operator, Falco, et Mend Renovate, en compl\u00e9ment \u00e0 Dependabot, constitue un renforcement significatif de notre strat\u00e9gie de s\u00e9curit\u00e9, permettant d'aborder de mani\u00e8re proactive et en temps r\u00e9el les vuln\u00e9rabilit\u00e9s dans notre infrastructure Kubernetes. Cette strat\u00e9gie multilat\u00e9rale, soutenue par une visualisation claire via Grafana, garantit que nous maintenons une posture de s\u00e9curit\u00e9 solide, essentielle pour la fiabilit\u00e9 et la performance de nos services.</p>"},{"location":"adr/017-security.fr-ca/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Falco</li> <li>Trivy</li> <li>MEND Renovate</li> <li>Dependabot</li> <li>Snyk</li> <li>Sysdig secure</li> </ul>"}]}